{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "environment": {
      "name": "pytorch-gpu.1-4.m46",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "CIFAR10_Kerv.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WtSDEw_bScAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets,transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "plt.rcParams[\"figure.figsize\"]= 15,10\n",
        "#from layer import KernelConv2d, GaussianKernel, PolynomialKernel\n",
        "from functools import partial # To invoke Kernel objects with input parameters when creating KernelConv2d object (e.g. partial(GaussianKernel, 0.05) for Gaussian OR partial(PolynomialKernel,2,3) for Polynomial)\n",
        "%matplotlib inline\n",
        "def mkdirs(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1Uk66W0zScA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 17\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y0zhMJFWScA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class lr_find():\n",
        "#     min_lr, max_lr, steps_per_epoch, epochs\n",
        "    def __init__(self, optimizer,model ,criterion,train_loader, val_loader=None ,min_lr= 1e-6, max_lr= 1e-1, num_iter=100, steps_per_epoch=None, epochs=None,device=None):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.min_lr= min_lr\n",
        "        self.max_lr=max_lr\n",
        "        self.total_iterations = num_iter\n",
        "        self.history={}\n",
        "        self.iteration=0\n",
        "        self.optimizer= optimizer\n",
        "        self.model = model\n",
        "        self.iter_wrapper = DataLoaderIterWrapper(train_loader)\n",
        "        self.val_loader=val_loader\n",
        "        self.criterion=criterion\n",
        "        \n",
        "        self.model_device = next(self.model.parameters()).device\n",
        "        \n",
        "        \n",
        "        if device:\n",
        "            self.device = device\n",
        "        else:\n",
        "            self.device = self.model_device\n",
        "            \n",
        "            \n",
        "        if min_lr:\n",
        "            self.set_min_lr()\n",
        "        \n",
        "                \n",
        "        \n",
        "        \n",
        "    def train_batch(self, iter_wrapper, acc_steps = 1):\n",
        "        self.model.train()\n",
        "        \n",
        "        total_loss = None\n",
        "        self.optimizer.zero_grad()\n",
        "    \n",
        "        for  i in range(acc_steps):   \n",
        "            inputs, labels = next(iter_wrapper)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            \n",
        "            outputs = self.model(inputs)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "            loss/= acc_steps\n",
        "            \n",
        "            loss.backward()\n",
        "            if total_loss is None:\n",
        "                total_loss = loss\n",
        "            else:\n",
        "                total_loss+=loss\n",
        "        self.optimizer.step()\n",
        "        \n",
        "        return total_loss.item()\n",
        "    \n",
        "   \n",
        "    def _validate(self, data_loader):\n",
        "        running_loss=0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in data_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                batch_size = inputs.size(0)\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                running_loss+= loss.item() * batch_size\n",
        "                \n",
        "        return running_loss / len(data_loader.dataset) # Avg. loss per observation   \n",
        "        \n",
        "        \n",
        "        \n",
        "    def current_lr(self):\n",
        "        x = self.iteration / self.total_iterations\n",
        "        lr = self.min_lr + (self.max_lr - self.min_lr) * x\n",
        "        return lr\n",
        "    \n",
        "    def set_min_lr(self, logs=None):\n",
        "        self.optimizer.param_groups[0][\"lr\"] = self.min_lr\n",
        "    \n",
        "    \n",
        "    def run_test(self ):\n",
        "        \n",
        "        for iter_ in  tqdm(range(self.total_iterations)):\n",
        "            \n",
        "            self.iteration+=1\n",
        "\n",
        "\n",
        "            self.history.setdefault(\"lr\", []).append(self.optimizer.param_groups[0][\"lr\"])\n",
        "            self.history.setdefault(\"iterations\", []).append(self.iteration)\n",
        "            \n",
        "            if self.val_loader:\n",
        "                self.history.setdefault(\"loss\", []).append(self._validate(self.val_loader))\n",
        "            else:\n",
        "                self.history.setdefault(\"loss\", []).append(self.train_batch(self.iter_wrapper))\n",
        "\n",
        "\n",
        "            self.optimizer.param_groups[0][\"lr\"] = self.current_lr()\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def plot_lr(self):\n",
        "        '''Helper function to quickly inspect the learning rate schedule.'''\n",
        "        plt.plot(self.history['iterations'], self.history['lr'])\n",
        "        plt.yscale('log')\n",
        "        plt.xlabel('Iteration')\n",
        "        plt.ylabel('Learning rate')\n",
        "        plt.show()\n",
        "        \n",
        "    def plot_loss(self):\n",
        "        '''Helper function to quickly observe the learning rate experiment results.'''\n",
        "        plt.plot(self.history['lr'], self.history['loss'])\n",
        "        plt.xscale('log')\n",
        "        plt.xlabel('Learning rate')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.show()\n",
        "        \n",
        "        \n",
        "   \n",
        "class DataLoaderIterWrapper(object):\n",
        "    \"\"\"A wrapper for iterating `torch.utils.data.DataLoader` with the ability to reset\n",
        "    itself while `StopIteration` is raised.\"\"\"\n",
        "\n",
        "    def __init__(self, data_loader, auto_reset=True):\n",
        "        self.data_loader = data_loader\n",
        "        self.auto_reset = auto_reset\n",
        "        self._iterator = iter(data_loader)\n",
        "\n",
        "    def __next__(self):\n",
        "        # Get a new set of inputs and labels\n",
        "        try:\n",
        "            inputs, labels, *_ = next(self._iterator)\n",
        "        except StopIteration:\n",
        "            if not self.auto_reset:\n",
        "                raise\n",
        "            self._iterator = iter(self.data_loader)\n",
        "            inputs, labels, *_ = next(self._iterator)\n",
        "\n",
        "        return inputs, labels\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OUTwIYeyScA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Kernel(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel,kernelsize,kernel_fn, c=1.0,degree=5,gamma = 0.5,rhok=0.02, padding=0):\n",
        "        super(Kernel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channel,out_channel,kernelsize, padding=padding)\n",
        "        \n",
        "        \n",
        "        \n",
        "        if kernel_fn == 0:            \n",
        "            self.c = torch.nn.parameter.Parameter(torch.tensor(c), requires_grad=False)\n",
        "            self.degree = torch.nn.parameter.Parameter(torch.tensor(degree), requires_grad=False)\n",
        "        \n",
        "        if kernel_fn == 1:\n",
        "            self.gamma = torch.nn.parameter.Parameter(torch.tensor(gamma), requires_grad=False)\n",
        "        \n",
        "        if kernel_fn >= 3:\n",
        "            self.rho = torch.nn.parameter.Parameter(torch.tensor(rhok, requires_grad=True))   \n",
        "            self.c = torch.nn.parameter.Parameter(torch.tensor(c), requires_grad=False)\n",
        "            self.degree = torch.nn.parameter.Parameter(torch.tensor(degree), requires_grad=False)\n",
        "            self.gamma = torch.nn.parameter.Parameter(torch.tensor(gamma), requires_grad=False)\n",
        "        \n",
        "        self.in_channel = in_channel\n",
        "        self.out_channel = out_channel\n",
        "        self.kernelsize = kernelsize\n",
        "        self.kernel_fn= kernel_fn\n",
        " \n",
        "    \n",
        "    def __compute_shape(self, x):\n",
        "        h = (x.shape[2] - self.conv1.kernel_size[0] + 2 * self.conv1.padding[0]) // self.conv1.stride[0] + 1\n",
        "        w = (x.shape[3] - self.conv1.kernel_size[1] + 2 * self.conv1.padding[1]) // self.conv1.stride[1] + 1\n",
        "        return h, w\n",
        "        \n",
        "    def convolution(self,x):\n",
        "        return self.conv1(x)\n",
        "    def sigmoidkerv(self,x):\n",
        "        return torch.tanh(self.convolution(x))\n",
        "    \n",
        "    def polynomial(self,x):\n",
        "#         print(torch.max(self.convolution(x)))\n",
        "#         print(torch.min(self.convolution(x)))\n",
        "#         print(torch.max((self.convolution(x) + self.c) ** self.degree))\n",
        "#         print(torch.min((self.convolution(x) + self.c) ** self.degree))\n",
        "        return (self.convolution(x) + self.c) ** self.degree\n",
        "    \n",
        "    def gaussian(self,x):        \n",
        "        x_unf = F.unfold(x, self.conv1.kernel_size, self.conv1.dilation, self.conv1.padding, self.conv1.stride).transpose(1, 2)\n",
        "        h, w = self.__compute_shape(x)\n",
        "        l2 = x_unf.unsqueeze(3) - self.conv1.weight.view(1, 1, -1, self.conv1.weight.size(0))\n",
        "        l2 = torch.sum(l2 ** 2, 2)\n",
        "        out =  torch.exp(-self.gamma * l2)\n",
        "        if self.conv1.bias is not None:\n",
        "            out = out + self.conv1.bias\n",
        "        return out.view(x.shape[0], self.conv1.out_channels, w, h)\n",
        "\n",
        "    def polyconv(self,x):\n",
        "        conv = self.convolution(x)\n",
        "        poly = torch.clamp(((conv + self.c) ** self.degree), min = 1e-10, max= 1e10)\n",
        "        return torch.sigmoid(self.rho)*(poly) + (1-torch.sigmoid(self.rho))*conv\n",
        "    \n",
        "    def polysigm(self,x):\n",
        "        conv = self.convolution(x)\n",
        "        return torch.sigmoid(self.rho)*((conv + self.c) ** self.degree) + (1-torch.sigmoid(self.rho))*torch.tanh(conv)\n",
        "        \n",
        "    def kernel_fn_a(self, x):\n",
        "        #Polynomial\n",
        "        return F.relu(self.polynomial(x))\n",
        "    \n",
        "    def kernel_fn_b(self,x):\n",
        "        #Gaussian\n",
        "        return F.relu(self.gaussian(x))\n",
        "    \n",
        "    def kernel_fn_c(self, x):\n",
        "        #Sigmoid\n",
        "        return F.relu(self.sigmoidkerv(x))\n",
        "    \n",
        "    def kernel_fn_d(self, x):\n",
        "        #Polynomial + Convolution\n",
        "        return F.relu(self.polyconv(x))\n",
        "    \n",
        "    def kernel_fn_e(self, x):\n",
        "        #Sigmoid + Convolution\n",
        "        conv = self.convolution(x)\n",
        "        return F.relu(torch.sigmoid(self.rho)*torch.tanh(conv) + (1- torch.sigmoid(self.rho)) * conv)\n",
        "        \n",
        "    def kernel_fn_f(self, x):\n",
        "        #Gaussian + Convolution\n",
        "        return F.relu(torch.sigmoid(self.rho)*self.gaussian(x) + (1- torch.sigmoid(self.rho)) * self.convolution(x))\n",
        "        \n",
        "    def kernel_fn_g(self, x):\n",
        "        #Gaussian + Polynomial\n",
        "        return F.relu(torch.sigmoid(self.rho)*self.gaussian(x) + (1- torch.sigmoid(self.rho)) * self.polynomial(x))\n",
        "      \n",
        "        \n",
        "    def kernel_fn_h(self, x):\n",
        "        #Gaussian + Sigmoid\n",
        "        return F.relu(torch.sigmoid(self.rho)*self.gaussian(x) + (1- torch.sigmoid(self.rho)) * self.sigmoidkerv(x))\n",
        "        \n",
        "    def kernel_fn_i(self, x):\n",
        "        #Polynomial + Sigmoid##\n",
        "        return F.relu(self.polysigm(x))\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        json = {0: self.kernel_fn_a ,1: self.kernel_fn_b ,2: self.kernel_fn_c ,\n",
        "                3: self.kernel_fn_d ,4: self.kernel_fn_e , 5: self.kernel_fn_f,\n",
        "                6: self.kernel_fn_g ,7: self.kernel_fn_h, 8: self.kernel_fn_i }\n",
        "    \n",
        "        function =  self.kernel_fn\n",
        "        return json[function](x)\n",
        "    \n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "r0ZzN8GgScA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ParallelKernelConv2d(torch.nn.Conv2d):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
        "                 dilation=1, groups=1, bias=False, padding_mode='zeros',c=1.0,degree=3,gamma = 0.5,rhok=0.02, a=1.0):\n",
        "        super(ParallelKernelConv2d, self).__init__(in_channels, out_channels, kernel_size, stride,\n",
        "                                           padding, dilation, groups, bias, padding_mode)\n",
        "#         self.kernel_fn = kernel_fn\n",
        "        self.conv1=torch.nn.Conv2d(in_channels, out_channels, kernel_size, padding = padding)\n",
        "#         self.convK1.weight = None#self.weight\n",
        "\n",
        "        self.conv1.bias = self.bias\n",
        "        self.conv1.weight = self.weight\n",
        "        \n",
        "        \n",
        "        self.a = torch.nn.parameter.Parameter(torch.tensor(a, requires_grad=True))\n",
        "        self.rho = torch.nn.parameter.Parameter(torch.tensor(rhok, requires_grad=True))   \n",
        "        self.c = torch.nn.parameter.Parameter(torch.tensor(c), requires_grad=False)\n",
        "        self.degree = torch.nn.parameter.Parameter(torch.tensor(degree), requires_grad=False)\n",
        "        \n",
        "#         self.rhoc1 = torch.nn.parameter.Parameter(torch.tensor(rhoc1, requires_grad=True))\n",
        "#         self.rhoc2 = torch.nn.parameter.Parameter(torch.tensor(rhoc2, requires_grad=True))\n",
        "        \n",
        "        self.conv2=torch.nn.Conv2d(in_channels, out_channels, kernel_size, padding = padding)\n",
        "#         self.convK1.weight = None#self.weight\n",
        "        if self.bias:\n",
        "            self.conv2.bias = a * self.bias\n",
        "        self.conv2.weight = a *  self.weight\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        conv = self.conv1(x)\n",
        "        poly = (self.conv2(x) + self.c) ** self.degree\n",
        "        return torch.sigmoid(self.rho)*(poly) + (1-torch.sigmoid(self.rho))*conv\n",
        "        \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ycRGaNkLScBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet5CIFAR10_Conv(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5CIFAR10_Conv,self).__init__()\n",
        "        self.conv1=nn.Conv2d(3,6,5 ) \n",
        "        self.conv2=nn.Conv2d(6,16,5 )  \n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
        "        x=x.reshape(-1,16*5*5)#x.view(-1,320)#320\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x,dim=1)\n",
        "    \n",
        "class LeNet5CIFAR10_Polynomial(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5CIFAR10_Polynomial,self).__init__()\n",
        "        self.conv1=Kernel(in_channel=3,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=0) \n",
        "        self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=0) \n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
        "        x=x.reshape(-1,16*5*5)#x.view(-1,320)#320\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x,dim=1)  \n",
        "    \n",
        "class LeNet5CIFAR10_Gaussian(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5CIFAR10_Gaussian,self).__init__()\n",
        "        self.conv1=Kernel(in_channel=3,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=1) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
        "        self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=1) \n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
        "        x=x.reshape(-1,16*5*5)#x.view(-1,320)#320\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x,dim=1)  \n",
        "    \n",
        "    \n",
        "class LeNet5CIFAR10_Sigmoid(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5CIFAR10_Sigmoid,self).__init__()\n",
        "        self.conv1=Kernel(in_channel=3,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=2) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
        "        self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=2) \n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
        "        x=x.reshape(-1,16*5*5)#x.view(-1,320)#320\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x,dim=1)  \n",
        "    \n",
        "class LeNet5CIFAR10_ConvPoly(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5CIFAR10_ConvPoly,self).__init__()\n",
        "        self.conv1=Kernel(in_channel=3,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=3) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
        "        self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=3) \n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
        "        x=x.reshape(-1,16*5*5)#x.view(-1,320)#320\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x,dim=1)\n",
        "    \n",
        "class LeNet5CIFAR10_ConvGauss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5CIFAR10_ConvGauss,self).__init__()\n",
        "        self.conv1=Kernel(in_channel=3,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=5) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
        "        self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=5) \n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
        "        x=x.reshape(-1,16*5*5)#x.view(-1,320)#320\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x,dim=1)  \n",
        "    \n",
        "\n",
        "class LeNet5CIFAR10_ConvSigmoid(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5CIFAR10_ConvSigmoid,self).__init__()\n",
        "        self.conv1=Kernel(in_channel=3,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=4) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
        "        self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=4) \n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
        "        x=x.reshape(-1,16*5*5)#x.view(-1,320)#320\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x,dim=1) \n",
        "    \n",
        "class LeNet5CIFAR10_SigmoidGauss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5CIFAR10_SigmoidGauss,self).__init__()\n",
        "        self.conv1=Kernel(in_channel=3,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=7) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
        "        self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=7) \n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
        "        x=x.reshape(-1,16*5*5)#x.view(-1,320)#320\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x,dim=1)  \n",
        "    \n",
        "class LeNet5CIFAR10_SigmoidPoly(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5CIFAR10_SigmoidPoly,self).__init__()\n",
        "        self.conv1=Kernel(in_channel=3,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=8) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
        "        self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=8) \n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
        "        x=x.reshape(-1,16*5*5)#x.view(-1,320)#320\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x,dim=1)    \n",
        "  \n",
        "\n",
        "class LeNet5CIFAR10_GaussPoly(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5CIFAR10_GaussPoly,self).__init__()\n",
        "        self.conv1=Kernel(in_channel=3,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=6) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
        "        self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=6) \n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
        "        x=x.reshape(-1,16*5*5)#x.view(-1,320)#320\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x,dim=1)  \n",
        "    \n",
        "    \n",
        "class LeNet5CIFAR10_Poly_Conv(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5CIFAR10_Poly_Conv,self).__init__()\n",
        "        self.conv1=Kernel(in_channel=3,out_channel= 6,kernelsize= 5,c=1.0,degree=3,kernel_fn=0) \n",
        "        self.conv2=nn.Conv2d(6,16,5) \n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
        "        x=x.reshape(-1,16*5*5)#x.view(-1,320)#320\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x,dim=1)  \n",
        "    \n",
        " \n",
        "class LeNet5CIFAR10_Conv_Poly(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5CIFAR10_Conv_Poly,self).__init__()\n",
        "        self.conv1=nn.Conv2d(3,6,5) \n",
        "        self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=3,kernel_fn=0)\n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
        "        x=x.reshape(-1,16*5*5)#x.view(-1,320)#320\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x,dim=1) \n",
        "    \n",
        "class LeNet5CIFAR10_ConvPoly_Conv(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5CIFAR10_ConvPoly_Conv,self).__init__()\n",
        "        self.conv1=Kernel(in_channel=3,out_channel= 6,kernelsize= 5,c=1.0,degree=3,kernel_fn=3) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
        "        self.conv2=nn.Conv2d(6,16,5) \n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
        "        x=x.reshape(-1,16*5*5)#x.view(-1,320)#320\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x,dim=1)\n",
        "    \n",
        "    \n",
        "class LeNet5CIFAR10_Conv_ConvPoly(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5CIFAR10_Conv_ConvPoly,self).__init__()\n",
        "        self.conv1=nn.Conv2d(3,6,5) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
        "        self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=3,kernel_fn=3) \n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
        "        x=x.reshape(-1,16*5*5)#x.view(-1,320)#320\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x,dim=1)\n",
        "\n",
        "    \n",
        "class LeNet5CIFAR10_Conv_Sigmoid(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5CIFAR10_Conv_Sigmoid,self).__init__()\n",
        "        self.conv1=nn.Conv2d(3,6,5) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
        "        self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=2) \n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
        "        x=x.reshape(-1,16*5*5)#x.view(-1,320)#320\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x,dim=1)\n",
        "    \n",
        "class LeNet5CIFAR10_Sigmoid_Conv(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5CIFAR10_Sigmoid_Conv,self).__init__()\n",
        "        self.conv1=Kernel(in_channel=3,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=2) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
        "        self.conv2=nn.Conv2d(6,16,5) \n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
        "        x=x.reshape(-1,16*5*5)#x.view(-1,320)#320\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x,dim=1)\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wp3I1AybScBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " F.relu(0.01 * torch.tensor([1e15, 234]) **3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "acTof8s-ScBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''VGG11/13/16/19 in Pytorch.'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "cfg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, vgg_name):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = self._make_layers(cfg[vgg_name])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        out = torch.clamp(F.log_softmax(out,dim=1), 1e-10,1)\n",
        "        out = torch.log(out)\n",
        "        return out\n",
        "\n",
        "    def _make_layers(self, cfg):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [ParallelKernelConv2d(in_channels= in_channels,out_channels= x,kernel_size= 3,padding=1, c=1.0,degree=3),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = VGG(\"VGG19\")\n",
        "    x = torch.randn(3,3,32,32)\n",
        "    y = net(x)\n",
        "#     make_dot(y)\n",
        "    print(y.size())\n",
        "    \n",
        "#     Kernel(in_channel= in_channels,out_channel= x,kernelsize= 3,padding=1, c=1.0,degree=5,kernel_fn=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GDYp9DK6ScBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.log(torch.tensor([0.23,0.111, 0.00001]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gyytTJUIScBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "W1lakmPYScBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import models\n",
        "model = VGG(\"VGG19\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vEMVQnxxScBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(model.conv1.kernel_fn._parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TLWkQMvEScBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    train_loader=torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10(\"data\",train=True,download=True,transform=transforms.Compose([\n",
        "                transforms.ToTensor(),torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "            ])),batch_size=128,shuffle=True)\n",
        "    test_loader=torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10(\"data\",train=False,download=True,transform=transforms.Compose([\n",
        "                transforms.ToTensor(), torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "                             ])),batch_size=128,shuffle=False)\n",
        "print(len(train_loader))\n",
        "print(len(test_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "v7NaYEbkScBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available () else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YqKP-a60ScBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss() \n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AqfXqKUJScBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer=optim.SGD(model.parameters(), lr=0.03)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PacFURcQScBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = torch.load(\"VGG19/VGG19_.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AKNxzBzgScBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# from tqdm import tqdm\n",
        "# lr_finder= lr_find(optimizer, model, criterion,train_loader= train_loader, device=device )\n",
        "# lr_finder.run_test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "v1rkZRUvScBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lr_finder.plot_loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "083RMxrhScBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer=optim.SGD(model.parameters(),lr=0.1, momentum=0.9, weight_decay=5e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "n3Ff7C-KScB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer.param_groups[0][\"weight_decay\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jcVQM8uYScB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_fY5KTIJScB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install barbar\n",
        "import time\n",
        "from barbar import Bar\n",
        "\n",
        "nb_epochs = 50\n",
        "# torch.manual_seed(42)\n",
        "\n",
        "\n",
        "def compute_accuray(pred,true):\n",
        "    pred_idx=pred.argmax(dim=1).detach().cpu().numpy()\n",
        "    tmp=pred_idx==true.cpu().numpy()\n",
        "    return (sum(tmp)/len(pred_idx))*100\n",
        "\n",
        "def plot_loss_epoch(train_loss, test_loss,epochs, model):\n",
        "    train, =plt.plot(range(1,epochs+1),train_loss, marker='o')\n",
        "    test, = plt.plot(range(1, epochs+1),test_loss,  marker=\"o\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend([train, test],[\"train_loss\",\"test_loss\"])\n",
        "    plt.title(\"Loss Vs Epoch for: \" + str(model))\n",
        "    plt.show()\n",
        "    \n",
        "def plot_accuracy_epoch(train_accuracy, test_accuracy,epochs, model):\n",
        "    train, =plt.plot(range(1,epochs+1),train_accuracy, marker=\"o\")\n",
        "#     print(train_accuracy)\n",
        "    test, = plt.plot(range(1, epochs+1),test_accuracy,  marker=\"o\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend([train, test],[\"train_accuracy\",\"test_accuracy\"])\n",
        "    plt.title(\"Accuracy Vs Epoch for: \" + str(model))\n",
        "    plt.show() \n",
        "\n",
        "def model_comparison(test_acc, times, epochs):\n",
        "    for model, acc in test_acc.items():\n",
        "        plt.plot(times[model],acc,  marker=\"o\")\n",
        "        plt.xlabel('Time')\n",
        "        plt.ylabel('Validation_Accuracy')\n",
        "        plt.title(\"Validation Accuracy Vs Time\")\n",
        "        plt.legend(test_acc.keys())\n",
        "        plt.show()\n",
        "    \n",
        "    for model, acc in test_acc.items():\n",
        "        plt.plot(range(1,epochs+1),acc,  marker=\"o\")\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Validation_Accuracy')\n",
        "        plt.title(\"Validation Accuracy Vs Epoch\")\n",
        "        plt.legend(test_acc.keys())\n",
        "        plt.show()\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "def train(m,out_dir):\n",
        "    iter_loss=[]\n",
        "    train_losses=[]\n",
        "    test_losses=[]\n",
        "    train_accuracy=[]\n",
        "    test_accuracy=[]\n",
        "    times = []\n",
        "    nan_output=[]\n",
        "    iter_loss_path=os.path.join(out_dir,\"iter_loss.csv\")\n",
        "    epoch_loss_path=os.path.join(out_dir,\"epoch_loss.csv\")\n",
        "    last_loss=99999\n",
        "    mkdirs(os.path.join(out_dir,\"models\"))\n",
        "    optimizer=optim.SGD(m.parameters(),lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "    start_time = time.time()\n",
        "    \n",
        "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr= 1e-6, max_lr= 1e-1, step_size_up=2000, step_size_down=None, \n",
        "                                                  mode='triangular2', gamma=1.0, scale_fn=None, scale_mode='cycle', cycle_momentum=True,\n",
        "                                                  base_momentum=0.8, max_momentum=0.9, last_epoch=-1)\n",
        "    \n",
        "    for epoch in range(nb_epochs):\n",
        "        train_loss=0.\n",
        "        train_acc=0.\n",
        "        m.train(mode=True)\n",
        "        for data,target in Bar(train_loader):\n",
        "            data,target=data.to(device),target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output=m(data)\n",
        "#             if (i==100):\n",
        "#                 print(\"train_output: \", output)\n",
        "            loss=criterion(output,target)\n",
        "            loss_value=loss.item()\n",
        "            iter_loss.append(loss_value)\n",
        "            train_loss+=loss_value\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(m.parameters(), 1)\n",
        "            optimizer.step()\n",
        "            acc=compute_accuray(torch.exp(output),target)\n",
        "            train_acc+=acc\n",
        "            \n",
        "            \n",
        "            scheduler.step()\n",
        "\n",
        "        train_losses.append(train_loss/len(train_loader))\n",
        "        train_accuracy.append(round(train_acc/len(train_loader),2))\n",
        "        \n",
        "        test_loss=0.\n",
        "        test_acc=0.\n",
        "        m.train(mode=False)\n",
        "        with torch.no_grad():\n",
        "            for data,target in test_loader:\n",
        "                data,target=data.to(device),target.to(device)\n",
        "                output=m(data)\n",
        "#                 print(i)\n",
        "#                 if i==50:\n",
        "#                     print(\"test output: \", output)\n",
        "                loss=criterion(output,target)\n",
        "                loss_value=loss.item()\n",
        "                if np.isnan(loss_value):\n",
        "                    print(\"loss: {}, output {} : \".format( loss_value, output))\n",
        "                iter_loss.append(loss_value)\n",
        "                test_loss+=loss_value\n",
        "                acc=compute_accuray(torch.exp(output),target)\n",
        "                test_acc+=acc\n",
        "            \n",
        "        time_elapsed = np.round(time.time() - start_time,2)\n",
        "        test_losses.append(test_loss/(len(test_loader)))\n",
        "        test_accuracy.append(round(test_acc/len(test_loader),2))\n",
        "        times.append(time_elapsed)\n",
        "        \n",
        "        print(\"Epoch {}: train loss is {}, train accuracy is {}; test loss is {}, test accuracy is {}, lr is: {},Weight_decay is {}\".\n",
        "              format(epoch,round(train_loss/len(train_loader),2),\n",
        "                     round(train_acc/len(train_loader),2),\n",
        "                     round(test_loss/len(test_loader),2),\n",
        "                     round(test_acc/len(test_loader),2),\n",
        "                     optimizer.param_groups[0]['lr'],\n",
        "                     optimizer.param_groups[0][\"weight_decay\"]))        \n",
        "        if test_loss/len(test_loader)<last_loss:      \n",
        "            name = str(out_dir) + '_' + \".pth\"\n",
        "            save_model_path=os.path.join(out_dir,name)\n",
        "            torch.save(m, save_model_path)\n",
        "            last_loss=test_loss/len(test_loader)\n",
        "        \n",
        "#     df=pd.DataFrame()\n",
        "#     df[\"iteration\"]=np.arange(0,len(iter_loss))\n",
        "#     df[\"loss\"]=iter_loss\n",
        "#     df.to_csv(iter_loss_path,index=False)\n",
        "    \n",
        "#     df=pd.DataFrame()\n",
        "#     df[\"epoch\"]=np.arange(0,nb_epochs)\n",
        "#     df[\"train_loss\"]=train_losses\n",
        "#     df[\"test_loss\"]=test_losses\n",
        "#     df.to_csv(epoch_loss_path,index=False)\n",
        "    \n",
        "    \n",
        "#     plot_accuracy_epoch(train_accuracy, test_accuracy, nb_epochs)\n",
        "#     plot_loss_epoch(train_losses, test_losses, nb_epochs)\n",
        "    \n",
        "    return train_accuracy, test_accuracy, train_losses, test_losses, times, nan_output\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CNvY3yhqScB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_accuracy, test_accuracy, train_losses, test_losses, times , nan_output= train(model, \"VGG19_ConvPoly\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2bMjPk12ScCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss= [2.3, np.nan, 2.45]\n",
        "for l in loss:\n",
        "    if l==np.nan:\n",
        "        print(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "boMrlslyScCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "torch.clamp(torch.tensor([np.nan, 23]), 0,1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "l7nSe50xScCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in nan_output[0]:\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SoHQgtq3ScCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report = pd.DataFrame({\"Epochs\":range(1,nb_epochs+1),\"Train_Accuracy\":train_accuracy, \"Test_Accuracy\":test_accuracy,\"Train_Loss\":train_losses,\"Test_Loss\":test_losses, \"Time\":times})\n",
        "report.to_csv(\"VGG19.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cNCv0kJyScCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_loss_epoch(train_losses, test_losses,epochs=80, model=VGG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0Hb50LiUScCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_accuracy_epoch(train_accuracy, test_accuracy,epochs=80, model=\"VGG19\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": false,
        "id": "Jv2k6aK4ScCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(model.conv1.convK1.weight[0:1,0:1])\n",
        "# print(model.conv1.weight[0:1,0:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": false,
        "id": "dPjEjdkmScCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(model.conv1.kernel_fn._parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": false,
        "id": "F9VukXnBScCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(model.conv1._parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BgFFw0-gScCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# import torch\n",
        "model = torch.load(\"/kaggle/input/New folder/LeNet5CIFAR10_Polynomial(1,3).pth\", map_location = torch.device(\"cpu\"))\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TI2TVmMrScCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.conv2._parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MGXhSfagScCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.sigmoid(torch.tensor(1.2526))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dVieuJhzScCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshowCIFAR10(img, label):\n",
        "  \n",
        "    img = img.numpy()\n",
        "    img = img.transpose(1,2,0)\n",
        "    print(label)\n",
        "    plt.axis(\"off\")\n",
        "    fig = plt.figure\n",
        "    plt.imshow(img, cmap=plt.cm.hot)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PN1Ms6LqScCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshowMNIST(img, label):\n",
        "  \n",
        "    img = img.numpy()\n",
        "    img = img.transpose(2,0,1)\n",
        "    print(label)\n",
        "    plt.axis(\"off\")\n",
        "    fig = plt.figure\n",
        "    plt.imshow(img, cmap=plt.cm.hot)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KneuT0SnScCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers= {\"conv1\": model.conv1.conv1, \"conv2\": model.conv2.conv1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9Keq8M8BScCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images= []\n",
        "labels=[]\n",
        "for img, label in train_loader:\n",
        "    images.append(img)\n",
        "    labels.append(label)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BoDF975bScC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(images[0][1].shape)\n",
        "# print(labels[0][1])\n",
        "image = images[0][7]\n",
        "label = labels[0][21]\n",
        "imshowCIFAR10(image,label)\n",
        "# images[0][1].numpy().transpose(1,2,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqczeVnwScC5",
        "colab_type": "text"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "id": "D1iEtMhXScC5",
        "colab_type": "text"
      },
      "source": [
        "#### Filter Maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yNj_4DxGScC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_filters_single_channel_big(t):\n",
        "    \n",
        "    #setting the rows and columns\n",
        "    nrows = t.shape[0]*t.shape[2]\n",
        "    ncols = t.shape[1]*t.shape[3]\n",
        "    \n",
        "    \n",
        "    npimg = np.array(t.numpy(), np.float32)\n",
        "    npimg = npimg.transpose((0, 2, 1, 3))\n",
        "    npimg = npimg.ravel().reshape(nrows, ncols)\n",
        "    \n",
        "    npimg = npimg.T\n",
        "    \n",
        "    fig, ax = plt.subplots()    \n",
        "    imgplot = sns.heatmap(npimg, xticklabels=False, yticklabels=False, cmap='gray', ax=ax, cbar=False)\n",
        "    \n",
        "    \n",
        "def plot_filters_single_channel(t):\n",
        "    \n",
        "    #kernels depth * number of kernels\n",
        "    nplots = t.shape[0]*t.shape[1]\n",
        "    ncols = 12\n",
        "    \n",
        "    nrows = 1 + nplots//ncols\n",
        "    #convert tensor to numpy image\n",
        "    npimg = np.array(t.numpy(), np.float32)\n",
        "    \n",
        "    count = 0\n",
        "    fig = plt.figure(figsize=(ncols, nrows))\n",
        "    \n",
        "    #looping through all the kernels in each channel\n",
        "    for i in range(t.shape[0]):\n",
        "        for j in range(t.shape[1]):\n",
        "            count += 1\n",
        "            ax1 = fig.add_subplot(nrows, ncols, count)\n",
        "            npimg = np.array(t[i, j].numpy(), np.float32)\n",
        "            npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
        "            npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
        "            ax1.imshow(npimg)\n",
        "            ax1.set_title(str(i) + ',' + str(j))\n",
        "            ax1.axis('off')\n",
        "            ax1.set_xticklabels([])\n",
        "            ax1.set_yticklabels([])\n",
        "   \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "def plot_filters_multi_channel(t):\n",
        "    \n",
        "    #get the number of kernals\n",
        "    num_kernels = t.shape[0]    \n",
        "    \n",
        "    #define number of columns for subplots\n",
        "    num_cols = 12\n",
        "    #rows = num of kernels\n",
        "    num_rows = num_kernels\n",
        "    \n",
        "    #set the figure size\n",
        "    fig = plt.figure(figsize=(num_cols,num_rows))\n",
        "    \n",
        "    #looping through all the kernels\n",
        "    for i in range(t.shape[0]):\n",
        "        ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
        "        \n",
        "        #for each kernel, we convert the tensor to numpy \n",
        "        npimg = np.array(t[i].numpy(), np.float32)\n",
        "        #standardize the numpy image\n",
        "        npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
        "        npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
        "        npimg = npimg.transpose((1, 2, 0))\n",
        "        ax1.imshow(npimg)\n",
        "        ax1.axis('off')\n",
        "        ax1.set_title(str(i))\n",
        "        ax1.set_xticklabels([])\n",
        "        ax1.set_yticklabels([])\n",
        "        \n",
        "    plt.savefig('myimage.png', dpi=100)    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "def plot_weights(model, layer_name, single_channel = True, collated = False):\n",
        "  \n",
        "  #extracting the model features at the particular layer number\n",
        "    layer = layers[layer_name]\n",
        "\n",
        "      #checking whether the layer is convolution layer or not \n",
        "    if isinstance(layer, nn.Conv2d):\n",
        "        #getting the weight tensor data\n",
        "        weight_tensor = layer.weight.data\n",
        "\n",
        "        if single_channel:\n",
        "            if collated:\n",
        "                plot_filters_single_channel_big(weight_tensor)\n",
        "            else:\n",
        "                plot_filters_single_channel(weight_tensor)\n",
        "\n",
        "        else:\n",
        "            print(weight_tensor.shape)\n",
        "            if weight_tensor.shape[1] == 3:\n",
        "                plot_filters_multi_channel(weight_tensor)\n",
        "            else:\n",
        "                print(\"Can only plot weights with three channels with single channel = False\")\n",
        "\n",
        "    else:\n",
        "        print(\"Can only visualize layers which are convolutional\")\n",
        "        \n",
        "#visualize weights for alexnet - first conv layer\n",
        "# plot_weights(alexnet, 0, single_channel = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2VkBmA_cScC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import seaborn as sns\n",
        "plot_weights(model = model, layer_name= \"conv1\", single_channel = True, collated = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-L3bSbi_ScDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_weights(model = model, layer_name= \"conv1\", single_channel = False, collated = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "u_4F_MnpScDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_weights(model = model, layer_name= \"conv1\", single_channel = True, collated = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SZ1kSuLLScDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_weights(model = model, layer_name= \"conv2\", single_channel = True, collated = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfwc8jxWScDL",
        "colab_type": "text"
      },
      "source": [
        "#### Occlusion Experiments\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZCI8-cDmScDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#custom function to conduct occlusion experiments\n",
        "\n",
        "def occlusion(model, image, label, occ_size = 15, occ_stride = 5, occ_pixel = 0.5):\n",
        "  \n",
        "    #get the width and height of the image\n",
        "    image_copy = image.reshape(28,28)\n",
        "    width, height = image_copy.shape[0], image_copy.shape[1]\n",
        "    print(width)\n",
        "    print(height)\n",
        "  \n",
        "    #setting the output image width and height\n",
        "    output_height = int(np.ceil((height-occ_size)/occ_stride))\n",
        "    print(\"output_height: \", output_height)\n",
        "    output_width = int(np.ceil((width-occ_size)/occ_stride))\n",
        "    print(\"output_width: \", output_width)\n",
        "    #create a white image of sizes we defined\n",
        "    heatmap = torch.zeros((output_height, output_width))\n",
        "    \n",
        "    #iterate all the pixels in each column\n",
        "    for h in range(0, height):\n",
        "        for w in range(0, width):\n",
        "            \n",
        "            h_start = h*occ_stride\n",
        "            w_start = w*occ_stride\n",
        "            h_end = min(height, h_start + occ_size)\n",
        "            w_end = min(width, w_start + occ_size)\n",
        "            \n",
        "            if (w_end) >= width or (h_end) >= height:\n",
        "                continue\n",
        "            \n",
        "            input_image = image.clone().detach()\n",
        "            input_image = input_image.reshape(1,1,28,28)\n",
        "            \n",
        "            #replacing all the pixel information in the image with occ_pixel(grey) in the specified location\n",
        "            input_image[:,:, w_start:w_end, h_start:h_end] = occ_pixel\n",
        "            \n",
        "            #run inference on modified image\n",
        "            \n",
        "            output = torch.exp(model(input_image))\n",
        "#             print(output.tolist())\n",
        "            prob = output.tolist()[0][label]\n",
        "            print(prob)\n",
        "            \n",
        "            #setting the heatmap location to probability value\n",
        "            heatmap[h, w] = prob \n",
        "\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FYqsjOKDScDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imshowMNIST(images[0][1],labels[0][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YtXEVaerScDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "heatmap =  occlusion(model, image, label.item())\n",
        "imgplot = sns.heatmap(heatmap, xticklabels=False, yticklabels=False)\n",
        "figure = imgplot.get_figure()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvkf-G4uScDS",
        "colab_type": "text"
      },
      "source": [
        "> ####  Activation Maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "P8qBvRKEScDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " list(model.children())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IQ9xnFVvScDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = {}\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "\n",
        "\n",
        "model.conv1.register_forward_hook(get_activation('conv1'))\n",
        "model.conv2.register_forward_hook(get_activation('conv2'))\n",
        "model.fc1.register_forward_hook(get_activation('fc1'))\n",
        "model.fc2.register_forward_hook(get_activation('fc2'))\n",
        "model.fc3.register_forward_hook(get_activation('fc3'))\n",
        "x = image.reshape(1,3,32,32)\n",
        "output = model(x)\n",
        "print(activation['conv1'].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hYuQ4aUZScDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# activation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LzSYr9y2ScDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "act = activation['conv1'].squeeze()\n",
        "print(act.shape)\n",
        "fig, axarr = plt.subplots(act.size(0), figsize=(10,10))\n",
        "for idx in range(act.size(0)):\n",
        "    axarr[idx].imshow(act[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3OQl6GZtScDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "act = activation['conv2'].squeeze()\n",
        "print(act.shape)\n",
        "fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(4,4))\n",
        "for ax, feature in zip(ax.flatten(), act):\n",
        "    ax.imshow(feature)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkBy-gVHScDo",
        "colab_type": "text"
      },
      "source": [
        "### Activation Maximization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "skFsyKyNScDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZU6iSiLzScDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Al5O_zUnScDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "c7xnvuAXScD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(model.children())[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SJQWIwJQScD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SaveFeatures():\n",
        "    def __init__(self, module):\n",
        "        self.hook = module.register_forward_hook(self.hook_fn)\n",
        "    def hook_fn(self, module, input, output):\n",
        "        self.features = torch.tensor(output,requires_grad=True).cuda()\n",
        "    def close(self):\n",
        "        self.hook.remove()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CGYzCOqdScD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activations = SaveFeatures(list(model.children())[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XMefUcBOScEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(model.children())[0].register_forward_hook()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5pkA3JD5ScED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activations.f[0, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "w9pqC99qScEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FilterVisualizer():\n",
        "    def __init__(self,  model,size=56, upscaling_steps=12, upscaling_factor=1.2):\n",
        "        self.size, self.upscaling_steps, self.upscaling_factor = size, upscaling_steps, upscaling_factor\n",
        "        self.model = model\n",
        "        self.model.eval()\n",
        "\n",
        "    def visualize(self, layer, filter, lr=0.1, opt_steps=20, blur=None):\n",
        "        sz = self.size\n",
        "        img = np.uint8(np.random.uniform(150, 180, (1,sz, sz)))/255  # generate random image\n",
        "        activations = SaveFeatures(list(self.model.children())[layer])  # register hook\n",
        "\n",
        "        for _ in range(self.upscaling_steps):  # scale the image up upscaling_steps times\n",
        "#             train_tfms, val_tfms = tfms_from_model(self.model, sz)\n",
        "            img_var = torch.tensor(img[None], dtype=torch.double,requires_grad=True)  # convert image to Variable that requires grad\n",
        "            optimizer = torch.optim.Adam([img_var], lr=lr, weight_decay=1e-6)\n",
        "            for n in range(opt_steps):  # optimize pixel values for opt_steps times\n",
        "                optimizer.zero_grad()\n",
        "                self.model(img_var)\n",
        "                loss = -activations.features[0, filter].mean()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            img = img_var.data.cpu().numpy()[0].transpose(1,2,0)\n",
        "            self.output = img\n",
        "            sz = int(self.upscaling_factor * sz)  # calculate new image size\n",
        "            img = cv2.resize(img, (sz, sz), interpolation = cv2.INTER_CUBIC)  # scale image up\n",
        "            if blur is not None: img = cv2.blur(img,(blur,blur))  # blur image to reduce high frequency patterns\n",
        "        self.save(layer, filter)\n",
        "        activations.close()\n",
        "        \n",
        "    def save(self, layer, filter):\n",
        "        plt.imsave(\"layer_\"+str(layer)+\"_filter_\"+str(filter)+\".jpg\", np.clip(self.output, 0, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GD61vzlQScEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer = 1\n",
        "filter = 2\n",
        "FV = FilterVisualizer(model, size=56, upscaling_steps=12, upscaling_factor=1.2)\n",
        "FV.visualize(layer, filter, blur=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "id": "LuCa4kqdScEJ",
        "colab_type": "text"
      },
      "source": [
        "#### Saliency Maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tMLK38yEScEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X=image.reshape(1,1,28,28)\n",
        "X.requires_grad_()\n",
        "scores = torch.exp(model(X))\n",
        "score_max_index = scores.argmax()\n",
        "score_max = scores[0,score_max_index]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XZH54dpxScEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_max.backward()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OSL5VdSLScER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saliency, _ = torch.max(X.grad.data.abs(),dim=1)\n",
        "\n",
        "\n",
        "# code to plot the saliency map as a heatmap\n",
        "plt.imshow(saliency[0], cmap=plt.cm.hot)\n",
        "# plt.imshow(images[0][1])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cpInWzukScET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imshowMNIST(images[0][1],labels[0][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lsYoN-KPScEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}