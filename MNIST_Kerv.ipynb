{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7m_ElK67qaqS"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available () else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lJhLpsi2qaqX"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "plt.rcParams[\"figure.figsize\"]= 15,10\n",
    "#from layer import KernelConv2d, GaussianKernel, PolynomialKernel\n",
    "from functools import partial # To invoke Kernel objects with input parameters when creating KernelConv2d object (e.g. partial(GaussianKernel, 0.05) for Gaussian OR partial(PolynomialKernel,2,3) for Polynomial)\n",
    "%matplotlib inline\n",
    "def mkdirs(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BbvBH9h3qaqa"
   },
   "outputs": [],
   "source": [
    "seed = 17\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nxwQhDHqaqh"
   },
   "outputs": [],
   "source": [
    "class Kernel(nn.Module):\n",
    "    def __init__(self,in_channel,out_channel,kernelsize,kernel_fn, c=1.0,degree=5,gamma = 0.5,rhok=0.02):\n",
    "        super(Kernel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel,out_channel,kernelsize)\n",
    "        \n",
    "        \n",
    "        if kernel_fn == 0:            \n",
    "            self.c = torch.nn.parameter.Parameter(torch.tensor(c), requires_grad=False)\n",
    "            self.degree = torch.nn.parameter.Parameter(torch.tensor(degree), requires_grad=False)\n",
    "        \n",
    "        if kernel_fn == 1:\n",
    "            self.gamma = torch.nn.parameter.Parameter(torch.tensor(gamma), requires_grad=False)\n",
    "        \n",
    "        if kernel_fn >= 3:\n",
    "            self.rho = torch.nn.parameter.Parameter(torch.tensor(rhok, requires_grad=True))   \n",
    "            self.c = torch.nn.parameter.Parameter(torch.tensor(c), requires_grad=False)\n",
    "            self.degree = torch.nn.parameter.Parameter(torch.tensor(degree), requires_grad=False)\n",
    "            self.gamma = torch.nn.parameter.Parameter(torch.tensor(gamma), requires_grad=False)\n",
    "        \n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.kernelsize = kernelsize\n",
    "        self.kernel_fn= kernel_fn\n",
    " \n",
    "    \n",
    "    def __compute_shape(self, x):\n",
    "        h = (x.shape[2] - self.conv1.kernel_size[0] + 2 * self.conv1.padding[0]) // self.conv1.stride[0] + 1\n",
    "        w = (x.shape[3] - self.conv1.kernel_size[1] + 2 * self.conv1.padding[1]) // self.conv1.stride[1] + 1\n",
    "        return h, w\n",
    "        \n",
    "    def convolution(self,x):\n",
    "        return self.conv1(x)\n",
    "        \n",
    "    def sigmoidkerv(self,x):\n",
    "        return torch.tanh(self.convolution(x))\n",
    "    \n",
    "    def polynomial(self,x):\n",
    "#         print(torch.max(self.convolution(x)))\n",
    "#         print(torch.min(self.convolution(x)))\n",
    "#         print(torch.max((self.convolution(x) + self.c) ** self.degree))\n",
    "#         print(torch.min((self.convolution(x) + self.c) ** self.degree))\n",
    "        return (self.convolution(x) + self.c) ** self.degree\n",
    "    \n",
    "    def gaussian(self,x):        \n",
    "        x_unf = F.unfold(x, self.conv1.kernel_size, self.conv1.dilation, self.conv1.padding, self.conv1.stride).transpose(1, 2)\n",
    "        h, w = self.__compute_shape(x)\n",
    "        l2 = x_unf.unsqueeze(3) - self.conv1.weight.view(1, 1, -1, self.conv1.weight.size(0))\n",
    "        l2 = torch.sum(l2 ** 2, 2)\n",
    "        out =  torch.exp(-self.gamma * l2)\n",
    "        if self.conv1.bias is not None:\n",
    "            out = out + self.conv1.bias\n",
    "        return out.view(x.shape[0], self.conv1.out_channels, w, h)\n",
    "\n",
    "    def polyconv(self,x):\n",
    "        conv = self.convolution(x)\n",
    "        return torch.sigmoid(self.rho)*((conv + self.c) ** self.degree) + (1-torch.sigmoid(self.rho))*conv\n",
    "    \n",
    "    def polysigm(self,x):\n",
    "        conv = self.convolution(x)\n",
    "        return torch.sigmoid(self.rho)*((conv + self.c) ** self.degree) + (1-torch.sigmoid(self.rho))*torch.tanh(conv)\n",
    "        \n",
    "    def kernel_fn_a(self, x):\n",
    "        #Polynomial\n",
    "        return F.relu(self.polynomial(x))\n",
    "    \n",
    "    def kernel_fn_b(self,x):\n",
    "        #Gaussian\n",
    "        return F.relu(self.gaussian(x))\n",
    "    \n",
    "    def kernel_fn_c(self, x):\n",
    "        #Sigmoid\n",
    "        return F.relu(self.sigmoidkerv(x))\n",
    "    \n",
    "    def kernel_fn_d(self, x):\n",
    "        #Polynomial + Convolution\n",
    "        return F.relu(self.polyconv(x))\n",
    "    \n",
    "    def kernel_fn_e(self, x):\n",
    "        #Sigmoid + Convolution\n",
    "        conv = self.convolution(x)\n",
    "        return F.relu(torch.sigmoid(self.rho)*torch.tanh(conv) + (1- torch.sigmoid(self.rho)) * conv)\n",
    "        \n",
    "    def kernel_fn_f(self, x):\n",
    "        #Gaussian + Convolution\n",
    "        return F.relu(torch.sigmoid(self.rho)*self.gaussian(x) + (1- torch.sigmoid(self.rho)) * self.convolution(x))\n",
    "        \n",
    "    def kernel_fn_g(self, x):\n",
    "        #Gaussian + Polynomial\n",
    "        return F.relu(torch.sigmoid(self.rho)*self.gaussian(x) + (1- torch.sigmoid(self.rho)) * self.polynomial(x))\n",
    "      \n",
    "        \n",
    "    def kernel_fn_h(self, x):\n",
    "        #Gaussian + Sigmoid\n",
    "        return F.relu(torch.sigmoid(self.rho)*self.gaussian(x) + (1- torch.sigmoid(self.rho)) * self.sigmoidkerv(x))\n",
    "        \n",
    "    def kernel_fn_i(self, x):\n",
    "        #Polynomial + Sigmoid##\n",
    "        return F.relu(self.polysigm(x))\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        json = {0: self.kernel_fn_a ,1: self.kernel_fn_b ,2: self.kernel_fn_c ,\n",
    "                3: self.kernel_fn_d ,4: self.kernel_fn_e , 5: self.kernel_fn_f,\n",
    "                6: self.kernel_fn_g ,7: self.kernel_fn_h, 8: self.kernel_fn_i }\n",
    "    \n",
    "        function =  self.kernel_fn\n",
    "        return json[function](x)\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wWTF8j8-qaqn"
   },
   "outputs": [],
   "source": [
    "class Kernel_norelu(nn.Module):\n",
    "    def __init__(self,in_channel,out_channel,kernelsize,kernel_fn, c=1.0,degree=5,gamma = 0.5,rhok=0.02):\n",
    "        super(Kernel_norelu, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel,out_channel,kernelsize)\n",
    "        \n",
    "        \n",
    "        if kernel_fn == 0:            \n",
    "            self.c = torch.nn.parameter.Parameter(torch.tensor(c), requires_grad=False)\n",
    "            self.degree = torch.nn.parameter.Parameter(torch.tensor(degree), requires_grad=False)\n",
    "        \n",
    "        if kernel_fn == 1:\n",
    "            self.gamma = torch.nn.parameter.Parameter(torch.tensor(gamma), requires_grad=False)\n",
    "        \n",
    "        if kernel_fn >= 3:\n",
    "            self.rho = torch.nn.parameter.Parameter(torch.tensor(rhok, requires_grad=True))   \n",
    "            self.c = torch.nn.parameter.Parameter(torch.tensor(c), requires_grad=False)\n",
    "            self.degree = torch.nn.parameter.Parameter(torch.tensor(degree), requires_grad=False)\n",
    "            self.gamma = torch.nn.parameter.Parameter(torch.tensor(gamma), requires_grad=False)\n",
    "        \n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.kernelsize = kernelsize\n",
    "        self.kernel_fn= kernel_fn\n",
    " \n",
    "    \n",
    "    def __compute_shape(self, x):\n",
    "        h = (x.shape[2] - self.conv1.kernel_size[0] + 2 * self.conv1.padding[0]) // self.conv1.stride[0] + 1\n",
    "        w = (x.shape[3] - self.conv1.kernel_size[1] + 2 * self.conv1.padding[1]) // self.conv1.stride[1] + 1\n",
    "        return h, w\n",
    "        \n",
    "    def convolution(self,x):\n",
    "        return (self.conv1(x))\n",
    "    def sigmoidkerv(self,x):\n",
    "        return torch.tanh(self.convolution(x))\n",
    "    \n",
    "    def polynomial(self,x):\n",
    "#         print(torch.max(self.convolution(x)))\n",
    "#         print(torch.min(self.convolution(x)))\n",
    "#         print(torch.max((self.convolution(x) + self.c) ** self.degree))\n",
    "#         print(torch.min((self.convolution(x) + self.c) ** self.degree))\n",
    "        return (self.convolution(x) + self.c) ** self.degree\n",
    "    \n",
    "    def gaussian(self,x):        \n",
    "        x_unf = F.unfold(x, self.conv1.kernel_size, self.conv1.dilation, self.conv1.padding, self.conv1.stride).transpose(1, 2)\n",
    "        h, w = self.__compute_shape(x)\n",
    "        l2 = x_unf.unsqueeze(3) - self.conv1.weight.view(1, 1, -1, self.conv1.weight.size(0))\n",
    "        l2 = torch.sum(l2 ** 2, 2)\n",
    "        out =  torch.exp(-self.gamma * l2)\n",
    "        if self.conv1.bias is not None:\n",
    "            out = out + self.conv1.bias\n",
    "        return out.view(x.shape[0], self.conv1.out_channels, w, h)\n",
    "\n",
    "    def polyconv(self,x):\n",
    "        conv = self.convolution(x)\n",
    "        return torch.sigmoid(self.rho)*((conv + self.c) ** self.degree) + (1-torch.sigmoid(self.rho))*(conv)\n",
    "    \n",
    "    def polysigm(self,x):\n",
    "        conv = self.convolution(x)\n",
    "        return torch.sigmoid(self.rho)*((conv + self.c) ** self.degree) + (1-torch.sigmoid(self.rho))*torch.tanh(conv)\n",
    "        \n",
    "    def kernel_fn_a(self, x):\n",
    "        #Polynomial\n",
    "        return (self.polynomial(x))\n",
    "    \n",
    "    def kernel_fn_b(self,x):\n",
    "        #Gaussian\n",
    "        return (self.gaussian(x))\n",
    "    \n",
    "    def kernel_fn_c(self, x):\n",
    "        #Sigmoid\n",
    "        return (self.sigmoidkerv(x))\n",
    "    \n",
    "    def kernel_fn_d(self, x):\n",
    "        #Polynomial + Convolution\n",
    "        return (self.polyconv(x))\n",
    "    \n",
    "    def kernel_fn_e(self, x):\n",
    "        #Sigmoid + Convolution\n",
    "        conv = self.convolution(x)\n",
    "        return (torch.sigmoid(self.rho)*torch.tanh(conv) + (1- torch.sigmoid(self.rho)) * (conv))\n",
    "        \n",
    "    def kernel_fn_f(self, x):\n",
    "        #Gaussian + Convolution\n",
    "        return (torch.sigmoid(self.rho)*self.gaussian(x) + (1- torch.sigmoid(self.rho)) * (self.convolution(x)))\n",
    "        \n",
    "    def kernel_fn_g(self, x):\n",
    "        #Gaussian + Polynomial\n",
    "        return (torch.sigmoid(self.rho)*self.gaussian(x) + (1- torch.sigmoid(self.rho)) * self.polynomial(x))\n",
    "      \n",
    "        \n",
    "    def kernel_fn_h(self, x):\n",
    "        #Gaussian + Sigmoid\n",
    "        return (torch.sigmoid(self.rho)*self.gaussian(x) + (1- torch.sigmoid(self.rho)) * self.sigmoidkerv(x))\n",
    "        \n",
    "    def kernel_fn_i(self, x):\n",
    "        #Polynomial + Sigmoid##\n",
    "        return (self.polysigm(x))\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        json = {0: self.kernel_fn_a ,1: self.kernel_fn_b ,2: self.kernel_fn_c ,\n",
    "                3: self.kernel_fn_d ,4: self.kernel_fn_e , 5: self.kernel_fn_f,\n",
    "                6: self.kernel_fn_g ,7: self.kernel_fn_h, 8: self.kernel_fn_i }\n",
    "    \n",
    "        function =  self.kernel_fn\n",
    "        return json[function](x)\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JKa8rw2fqaqq"
   },
   "outputs": [],
   "source": [
    "# class LeNet5MNIST_Conv(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet5MNIST_Conv,self).__init__()\n",
    "#         self.conv1=nn.Conv2d(1,6,5 ) \n",
    "#         self.conv2=nn.Conv2d(6,16,5 )  \n",
    "#         self.fc1=nn.Linear(16*4*4,120)\n",
    "#         self.fc2=nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
    "#         x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
    "#         x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "#         x=F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "#         return F.log_softmax(x,dim=1)\n",
    "    \n",
    "# class LeNet5MNIST_Polynomial(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet5MNIST_Polynomial,self).__init__()\n",
    "#         self.conv1=Kernel(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=3,kernel_fn=0) \n",
    "#         self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=3,kernel_fn=0) \n",
    "#         self.fc1=nn.Linear(16*4*4,120)\n",
    "#         self.fc2=nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
    "#         x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
    "#         x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "#         x=F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "#         return F.log_softmax(x,dim=1)  \n",
    "    \n",
    "# class LeNet5MNIST_Gaussian(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet5MNIST_Gaussian,self).__init__()\n",
    "#         self.conv1=Kernel(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=1) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "#         self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=1) \n",
    "#         self.fc1=nn.Linear(16*4*4,120)\n",
    "#         self.fc2=nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
    "#         x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
    "#         x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "#         x=F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "#         return F.log_softmax(x,dim=1)  \n",
    "    \n",
    "    \n",
    "# class LeNet5MNIST_Sigmoid(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet5MNIST_Sigmoid,self).__init__()\n",
    "#         self.conv1=Kernel(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=2) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "#         self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=2) \n",
    "#         self.fc1=nn.Linear(16*4*4,120)\n",
    "#         self.fc2=nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
    "#         x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
    "#         x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "#         x=F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "#         return F.log_softmax(x,dim=1)  \n",
    "    \n",
    "# class LeNet5MNIST_ConvPoly(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet5MNIST_ConvPoly,self).__init__()\n",
    "#         self.conv1=Kernel(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=3,kernel_fn=3) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "#         self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=3,kernel_fn=3) \n",
    "#         self.fc1=nn.Linear(16*4*4,120)\n",
    "#         self.fc2=nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
    "#         x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
    "#         x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "#         x=F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "#         return F.log_softmax(x,dim=1)\n",
    "    \n",
    "# class LeNet5MNIST_ConvGauss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet5MNIST_ConvGauss,self).__init__()\n",
    "#         self.conv1=Kernel(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=5) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "#         self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=5) \n",
    "#         self.fc1=nn.Linear(16*4*4,120)\n",
    "#         self.fc2=nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
    "#         x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
    "#         x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "#         x=F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "#         return F.log_softmax(x,dim=1)  \n",
    "    \n",
    "\n",
    "# class LeNet5MNIST_ConvSigmoid(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet5MNIST_ConvSigmoid,self).__init__()\n",
    "#         self.conv1=Kernel(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=4) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "#         self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=4) \n",
    "#         self.fc1=nn.Linear(16*4*4,120)\n",
    "#         self.fc2=nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
    "#         x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
    "#         x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "#         x=F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "#         return F.log_softmax(x,dim=1) \n",
    "    \n",
    "# class LeNet5MNIST_SigmoidGauss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet5MNIST_SigmoidGauss,self).__init__()\n",
    "#         self.conv1=Kernel(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=7) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "#         self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=7) \n",
    "#         self.fc1=nn.Linear(16*4*4,120)\n",
    "#         self.fc2=nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
    "#         x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
    "#         x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "#         x=F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "#         return F.log_softmax(x,dim=1)  \n",
    "    \n",
    "# class LeNet5MNIST_SigmoidPoly(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet5MNIST_SigmoidPoly,self).__init__()\n",
    "#         self.conv1=Kernel(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=3,kernel_fn=8) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "#         self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=3,kernel_fn=8) \n",
    "#         self.fc1=nn.Linear(16*4*4,120)\n",
    "#         self.fc2=nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
    "#         x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
    "#         x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "#         x=F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "#         return F.log_softmax(x,dim=1)    \n",
    "  \n",
    "\n",
    "# class LeNet5MNIST_GaussPoly(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet5MNIST_GaussPoly,self).__init__()\n",
    "#         self.conv1=Kernel(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=3,kernel_fn=6) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "#         self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=3,kernel_fn=6) \n",
    "#         self.fc1=nn.Linear(16*4*4,120)\n",
    "#         self.fc2=nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
    "#         x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
    "#         x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "#         x=F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "#         return F.log_softmax(x,dim=1)  \n",
    "    \n",
    "    \n",
    "# class LeNet5MNIST_Poly_Conv(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet5MNIST_Poly_Conv,self).__init__()\n",
    "#         self.conv1=Kernel(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=3,kernel_fn=0) \n",
    "#         self.conv2=nn.Conv2d(in_channel=6,out_channel= 16,kernelsize= 5) \n",
    "#         self.fc1=nn.Linear(16*4*4,120)\n",
    "#         self.fc2=nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
    "#         x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
    "#         x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "#         x=F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "#         return F.log_softmax(x,dim=1)  \n",
    "    \n",
    " \n",
    "# class LeNet5MNIST_Conv_Poly(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet5MNIST_Conv_Poly,self).__init__()\n",
    "#         self.conv1=nn.Conv2d(in_channel=1,out_channel= 6,kernelsize= 5) \n",
    "#         self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=3,kernel_fn=0)\n",
    "#         self.fc1=nn.Linear(16*4*4,120)\n",
    "#         self.fc2=nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
    "#         x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
    "#         x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "#         x=F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "#         return F.log_softmax(x,dim=1) \n",
    "    \n",
    "# class LeNet5MNIST_ConvPoly_Conv(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet5MNIST_ConvPoly_Conv,self).__init__()\n",
    "#         self.conv1=Kernel(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=3,kernel_fn=3) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "#         self.conv2=nn.Conv2d(in_channel=6,out_channel= 16,kernelsize= 5) \n",
    "#         self.fc1=nn.Linear(16*4*4,120)\n",
    "#         self.fc2=nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
    "#         x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
    "#         x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "#         x=F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "#         return F.log_softmax(x,dim=1)\n",
    "    \n",
    "    \n",
    "# class LeNet5MNIST_Conv_ConvPoly(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet5MNIST_Conv_ConvPoly,self).__init__()\n",
    "#         self.conv1=nn.Conv2d(in_channel=1,out_channel= 6,kernelsize= 5) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "#         self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=3,kernel_fn=3) \n",
    "#         self.fc1=nn.Linear(16*4*4,120)\n",
    "#         self.fc2=nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
    "#         x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
    "#         x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "#         x=F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "#         return F.log_softmax(x,dim=1)\n",
    "\n",
    "    \n",
    "# class LeNet5MNIST_Conv_Sigmoid(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet5MNIST_Conv_Sigmoid,self).__init__()\n",
    "#         self.conv1=nn.Conv2d(in_channel=1,out_channel= 6,kernelsize= 5) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "#         self.conv2=Kernel(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=2) \n",
    "#         self.fc1=nn.Linear(16*4*4,120)\n",
    "#         self.fc2=nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
    "#         x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
    "#         x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "#         x=F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "#         return F.log_softmax(x,dim=1)\n",
    "    \n",
    "# class LeNet5MNIST_Sigmoid_Conv(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet5MNIST_Sigmoid_Conv,self).__init__()\n",
    "#         self.conv1=Kernel(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=2) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "#         self.conv2=nn.Conv2d(in_channel=6,out_channel= 16,kernelsize= 5) \n",
    "#         self.fc1=nn.Linear(16*4*4,120)\n",
    "#         self.fc2=nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(F.max_pool2d(self.conv1(x),2,stride=2))\n",
    "#         x=F.relu(F.max_pool2d(self.conv2(x),2,stride=2))\n",
    "#         x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "#         x=F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc2(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "#         return F.log_softmax(x,dim=1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1d8WUEUVqaqy"
   },
   "outputs": [],
   "source": [
    "class LeNet5MNIST_Conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5MNIST_Conv,self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,6,5 ) \n",
    "        self.conv2=nn.Conv2d(6,16,5 )  \n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x=(F.avg_pool2d(self.conv1(x),2,stride=2))\n",
    "        x=(F.avg_pool2d(self.conv2(x),2,stride=2))\n",
    "        x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "        x=(self.fc1(x))\n",
    "        x=(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        return F.log_softmax(x,dim=1)\n",
    "    \n",
    "class LeNet5MNIST_Polynomial(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5MNIST_Polynomial,self).__init__()\n",
    "        self.conv1=Kernel_norelu(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=3,kernel_fn=0) \n",
    "        self.conv2=Kernel_norelu(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=3,kernel_fn=0) \n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x=(F.avg_pool2d(self.conv1(x),2,stride=2))\n",
    "        x=(F.avg_pool2d(self.conv2(x),2,stride=2))\n",
    "        x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "        x=(self.fc1(x))\n",
    "        x=(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        return F.log_softmax(x,dim=1)  \n",
    "    \n",
    "class LeNet5MNIST_Gaussian(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5MNIST_Gaussian,self).__init__()\n",
    "        self.conv1=Kernel_norelu(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=1) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "        self.conv2=Kernel_norelu(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=1) \n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x=(F.avg_pool2d(self.conv1(x),2,stride=2))\n",
    "        x=(F.avg_pool2d(self.conv2(x),2,stride=2))\n",
    "        x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "        x=(self.fc1(x))\n",
    "        x=(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        return F.log_softmax(x,dim=1)  \n",
    "    \n",
    "    \n",
    "class LeNet5MNIST_Sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5MNIST_Sigmoid,self).__init__()\n",
    "        self.conv1=Kernel_norelu(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=2) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "        self.conv2=Kernel_norelu(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=2) \n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x=(F.avg_pool2d(self.conv1(x),2,stride=2))\n",
    "        x=(F.avg_pool2d(self.conv2(x),2,stride=2))\n",
    "        x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "        x=(self.fc1(x))\n",
    "        x=(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        return F.log_softmax(x,dim=1)  \n",
    "    \n",
    "class LeNet5MNIST_ConvPoly(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5MNIST_ConvPoly,self).__init__()\n",
    "        self.conv1=Kernel_norelu(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=3,kernel_fn=3) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "        self.conv2=Kernel_norelu(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=3,kernel_fn=3) \n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x=(F.avg_pool2d(self.conv1(x),2,stride=2))\n",
    "        x=(F.avg_pool2d(self.conv2(x),2,stride=2))\n",
    "        x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "        x=(self.fc1(x))\n",
    "        x=(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        return F.log_softmax(x,dim=1)\n",
    "    \n",
    "class LeNet5MNIST_ConvGauss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5MNIST_ConvGauss,self).__init__()\n",
    "        self.conv1=Kernel_norelu(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=5) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "        self.conv2=Kernel_norelu(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=5) \n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x=(F.avg_pool2d(self.conv1(x),2,stride=2))\n",
    "        x=(F.avg_pool2d(self.conv2(x),2,stride=2))\n",
    "        x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "        x=(self.fc1(x))\n",
    "        x=(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        return F.log_softmax(x,dim=1)  \n",
    "    \n",
    "\n",
    "class LeNet5MNIST_ConvSigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5MNIST_ConvSigmoid,self).__init__()\n",
    "        self.conv1=Kernel_norelu(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=4) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "        self.conv2=Kernel_norelu(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=4) \n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x=(F.avg_pool2d(self.conv1(x),2,stride=2))\n",
    "        x=(F.avg_pool2d(self.conv2(x),2,stride=2))\n",
    "        x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "        x=(self.fc1(x))\n",
    "        x=(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        return F.log_softmax(x,dim=1) \n",
    "    \n",
    "class LeNet5MNIST_SigmoidGauss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5MNIST_SigmoidGauss,self).__init__()\n",
    "        self.conv1=Kernel_norelu(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=7) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "        self.conv2=Kernel_norelu(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=7) \n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x=(F.avg_pool2d(self.conv1(x),2,stride=2))\n",
    "        x=(F.avg_pool2d(self.conv2(x),2,stride=2))\n",
    "        x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "        x=(self.fc1(x))\n",
    "        x=(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        return F.log_softmax(x,dim=1)  \n",
    "    \n",
    "class LeNet5MNIST_SigmoidPoly(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5MNIST_SigmoidPoly,self).__init__()\n",
    "        self.conv1=Kernel_norelu(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=3,kernel_fn=8) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "        self.conv2=Kernel_norelu(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=3,kernel_fn=8) \n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x=(F.avg_pool2d(self.conv1(x),2,stride=2))\n",
    "        x=(F.avg_pool2d(self.conv2(x),2,stride=2))\n",
    "        x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "        x=(self.fc1(x))\n",
    "        x=(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        return F.log_softmax(x,dim=1)    \n",
    "  \n",
    "\n",
    "class LeNet5MNIST_GaussPoly(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5MNIST_GaussPoly,self).__init__()\n",
    "        self.conv1=Kernel_norelu(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=3,kernel_fn=6) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "        self.conv2=Kernel_norelu(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=3,kernel_fn=6) \n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x=(F.avg_pool2d(self.conv1(x),2,stride=2))\n",
    "        x=(F.avg_pool2d(self.conv2(x),2,stride=2))\n",
    "        x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "        x=(self.fc1(x))\n",
    "        x=(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        return F.log_softmax(x,dim=1)  \n",
    "    \n",
    "    \n",
    "class LeNet5MNIST_Poly_Conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5MNIST_Poly_Conv,self).__init__()\n",
    "        self.conv1=Kernel_norelu(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=3,kernel_fn=0) \n",
    "        self.conv2=nn.Conv2d(in_channel=6,out_channel= 16,kernelsize= 5) \n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x=(F.avg_pool2d(self.conv1(x),2,stride=2))\n",
    "        x=(F.avg_pool2d(self.conv2(x),2,stride=2))\n",
    "        x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "        x=(self.fc1(x))\n",
    "        x=(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        return F.log_softmax(x,dim=1)  \n",
    "    \n",
    " \n",
    "class LeNet5MNIST_Conv_Poly(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5MNIST_Conv_Poly,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channel=1,out_channel= 6,kernelsize= 5) \n",
    "        self.conv2=Kernel_norelu(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=3,kernel_fn=0)\n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x=(F.avg_pool2d(self.conv1(x),2,stride=2))\n",
    "        x=(F.avg_pool2d(self.conv2(x),2,stride=2))\n",
    "        x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "        x=(self.fc1(x))\n",
    "        x=(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        return F.log_softmax(x,dim=1) \n",
    "    \n",
    "class LeNet5MNIST_ConvPoly_Conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5MNIST_ConvPoly_Conv,self).__init__()\n",
    "        self.conv1=Kernel_norelu(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=3,kernel_fn=3) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "        self.conv2=nn.Conv2d(in_channel=6,out_channel= 16,kernelsize= 5) \n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x=(F.avg_pool2d(self.conv1(x),2,stride=2))\n",
    "        x=(F.avg_pool2d(self.conv2(x),2,stride=2))\n",
    "        x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "        x=(self.fc1(x))\n",
    "        x=(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        return F.log_softmax(x,dim=1)\n",
    "    \n",
    "    \n",
    "class LeNet5MNIST_Conv_ConvPoly(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5MNIST_Conv_ConvPoly,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channel=1,out_channel= 6,kernelsize= 5) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "        self.conv2=Kernel_norelu(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=3,kernel_fn=3) \n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x=(F.avg_pool2d(self.conv1(x),2,stride=2))\n",
    "        x=(F.avg_pool2d(self.conv2(x),2,stride=2))\n",
    "        x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "        x=(self.fc1(x))\n",
    "        x=(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        return F.log_softmax(x,dim=1)\n",
    "\n",
    "    \n",
    "class LeNet5MNIST_Conv_Sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5MNIST_Conv_Sigmoid,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channel=1,out_channel= 6,kernelsize= 5) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "        self.conv2=Kernel_norelu(in_channel=6,out_channel= 16,kernelsize= 5,c=1.0,degree=5,kernel_fn=2) \n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x=(F.avg_pool2d(self.conv1(x),2,stride=2))\n",
    "        x=(F.avg_pool2d(self.conv2(x),2,stride=2))\n",
    "        x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "        x=(self.fc1(x))\n",
    "        x=(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        return F.log_softmax(x,dim=1)\n",
    "    \n",
    "class LeNet5MNIST_Sigmoid_Conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5MNIST_Sigmoid_Conv,self).__init__()\n",
    "        self.conv1=Kernel_norelu(in_channel=1,out_channel= 6,kernelsize= 5,c=1.0,degree=5,kernel_fn=2) # self.conv1=KernelConv2d(1,10,5) for default/Ploynomial kernel with default parameters\n",
    "        self.conv2=nn.Conv2d(in_channel=6,out_channel= 16,kernelsize= 5) \n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x=(F.avg_pool2d(self.conv1(x),2,stride=2))\n",
    "        x=(F.avg_pool2d(self.conv2(x),2,stride=2))\n",
    "        x=x.reshape(-1,16*4*4)#x.view(-1,320)#320\n",
    "        x=(self.fc1(x))\n",
    "        x=(self.fc2(x))\n",
    "        x=(self.fc3(x))\n",
    "        return F.log_softmax(x,dim=1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nQ2b2JV0qaq6",
    "outputId": "d45d0379-d54b-4050-f6d3-34a8b48d6081"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test():\n",
    "    net = LeNet5MNIST_ConvPoly()\n",
    "    x = torch.randn(1,1,28,28)\n",
    "    y = net(x)\n",
    "#     make_dot(y)\n",
    "    print(y.size())\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cONR_robqaq_"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "model = LeNet5MNIST_ConvPoly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e1uot7iOqarF"
   },
   "outputs": [],
   "source": [
    "# print(model.conv1.kernel_fn._parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403,
     "referenced_widgets": [
      "7dfccf0db5bc412483986ea19ac2de1d",
      "5291583f275b478a9949b39abae05af3",
      "fc3e3d5a8b5348b1aa4eb6965e1c6874",
      "2e6bc382ce8847078fb82e8054e66ea3",
      "369ef7765e944ea3b08c9eb7b2868d71",
      "096d7b40a4f044279267b42cdda8bfc8",
      "179909d4cbb4448cb72e040824f0821a",
      "07d69766a8e44091b382b02a26031162",
      "e9a428ee92d344ffb8b552b52724cdae",
      "d1bd301da7f14ce3b1efb9905affa766",
      "28b84acde55449559884a823b9702987",
      "e050029c75ad4d858ae2d1c53f1c1b36",
      "c4eca6acf341433db0b9343d9de690c8",
      "9d518aecab0c40fc93825956e70680dd",
      "187485a346c84d049186ef2b2ba71a9f",
      "99d802a9e0434549a7f73b26e0b7f1f3",
      "0d23f105711f414cade3a9de2a39d144",
      "5e811c3e7eca416990d2c7ac975e3a30",
      "d278877619a14ee48b67a9255466b6e5",
      "02aeac86178e43b18e0efb5eab42a22b",
      "7c9500cf7d6d4bb3b376c1e44bd21cab",
      "3de48ae8713d4373a021c508777b0e90",
      "67d18c7024e64d9a822bb13fa8643c5e",
      "d306ce7f003b4668a0f3ff8d446ccaec",
      "b2029f13840c42ed8b5c556a021ae6d4",
      "b941015c9f6b4526836602515ffebcc9",
      "5f8cb837ef1f4d2ca58f6cc790aa865b",
      "76efe726779b4ac2b9c53d3bffb622c6",
      "7871ae2e405c4f9c9003365c94523b4d",
      "8b83a3812c8445c5ad020d9c235dcadc",
      "4dda8be814c14afd81aaf1c13726ebd5",
      "727e12f3180b443696bbfa09949cde16"
     ]
    },
    "colab_type": "code",
    "id": "O7_VQDyDqarI",
    "outputId": "224eb84c-69ab-482b-b9bc-6a53f438d544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfccf0db5bc412483986ea19ac2de1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a428ee92d344ffb8b552b52724cdae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d23f105711f414cade3a9de2a39d144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2029f13840c42ed8b5c556a021ae6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n",
      "1200\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loader=torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"data\",train=True,download=True,transform=transforms.Compose([\n",
    "                transforms.ToTensor(),torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])),batch_size=50,shuffle=True)\n",
    "    test_loader=torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"data\",train=False,download=True,transform=transforms.Compose([\n",
    "                transforms.ToTensor(), torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])),batch_size=50,shuffle=False)\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WG13T1bpqarN"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available () else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "GnkFU8AwqarT",
    "outputId": "f33ff3b9-c3a4-4a6a-c8fa-3303441a4f2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5MNIST_ConvPoly(\n",
       "  (conv1): Kernel_norelu(\n",
       "    (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  )\n",
       "  (conv2): Kernel_norelu(\n",
       "    (conv1): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  )\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.NLLLoss() \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nCrpSFdkqarX"
   },
   "outputs": [],
   "source": [
    "# pytorch_total_learn_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# pytorch_total_learn_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBuCoOusqara"
   },
   "outputs": [],
   "source": [
    "# pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "# pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g1ogVPV0qard"
   },
   "outputs": [],
   "source": [
    "# model.conv1.conv1._parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x7F3asfwqarm"
   },
   "outputs": [],
   "source": [
    "# model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iM6wSakMqarq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yzTm2bvOqart"
   },
   "outputs": [],
   "source": [
    "# pytorch_total_params = sum(p.numel() for p in model.conv1._parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "97xY-5VWqarv",
    "outputId": "9644d56f-019d-4674-a038-b96792b3619f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting barbar\n",
      "  Downloading https://files.pythonhosted.org/packages/48/1f/9b69ce144f484cfa00feb09fa752139658961de6303ea592487738d0b53c/barbar-0.2.1-py3-none-any.whl\n",
      "Installing collected packages: barbar\n",
      "Successfully installed barbar-0.2.1\n"
     ]
    }
   ],
   "source": [
    "! pip install barbar\n",
    "import time\n",
    "from barbar import Bar\n",
    "\n",
    "nb_epochs=20\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def compute_accuray(pred,true):\n",
    "    pred_idx=pred.argmax(dim=1).detach().cpu().numpy()\n",
    "    tmp=pred_idx==true.cpu().numpy()\n",
    "    return (sum(tmp)/len(pred_idx))*100\n",
    "\n",
    "def plot_loss_epoch(train_loss, test_loss,epochs, model):\n",
    "    train, =plt.plot(range(1,epochs+1),train_loss, marker='o')\n",
    "    test, = plt.plot(range(1, epochs+1),test_loss,  marker=\"o\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend([train, test],[\"train_loss\",\"test_loss\"])\n",
    "    plt.title(\"Loss Vs Epoch for: \" + model)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_accuracy_epoch(train_accuracy, test_accuracy,epochs, model):\n",
    "    train, =plt.plot(range(1,epochs+1),train_accuracy, marker=\"o\")\n",
    "#     print(train_accuracy)\n",
    "    test, = plt.plot(range(1, epochs+1),test_accuracy,  marker=\"o\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend([train, test],[\"train_accuracy\",\"test_accuracy\"])\n",
    "    plt.title(\"Accuracy Vs Epoch for: \" + model)\n",
    "    plt.show() \n",
    "\n",
    "def model_comparison(test_acc, times, epochs):\n",
    "    for model, acc in test_acc.items():\n",
    "        plt.plot(times[model],acc,  marker=\"o\")\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Validation_Accuracy')\n",
    "        plt.title(\"Validation Accuracy Vs Time\")\n",
    "        plt.legend(test_acc.keys())\n",
    "        plt.show()\n",
    "    \n",
    "    for model, acc in test_acc.items():\n",
    "        plt.plot(range(1,epochs+1),acc,  marker=\"o\")\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Validation_Accuracy')\n",
    "        plt.title(\"Validation Accuracy Vs Epoch\")\n",
    "        plt.legend(test_acc.keys())\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def train(m,out_dir):\n",
    "    iter_loss=[]\n",
    "    train_losses=[]\n",
    "    test_losses=[]\n",
    "    train_accuracy=[]\n",
    "    test_accuracy=[]\n",
    "    times = []\n",
    "    \n",
    "    iter_loss_path=os.path.join(out_dir,\"iter_loss.csv\")\n",
    "    epoch_loss_path=os.path.join(out_dir,\"epoch_loss.csv\")\n",
    "    last_loss=99999\n",
    "    mkdirs(os.path.join(out_dir,\"models\"))\n",
    "    optimizer=optim.SGD(m.parameters(), lr=0.03)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5,18], gamma=0.1)\n",
    "    start_time = time.time()\n",
    "    for epoch in range(nb_epochs):\n",
    "        train_loss=0.\n",
    "        train_acc=0.\n",
    "        m.train(mode=True)\n",
    "        for data,target in Bar(train_loader):\n",
    "            data,target=data.to(device),target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output=m(data)\n",
    "            loss=criterion(output,target)\n",
    "            loss_value=loss.item()\n",
    "            iter_loss.append(loss_value)\n",
    "            train_loss+=loss_value\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(m.parameters(), 1)\n",
    "            optimizer.step()\n",
    "            acc=compute_accuray(torch.exp(output),target)\n",
    "            train_acc+=acc\n",
    "            \n",
    "            \n",
    "        scheduler.step()\n",
    "\n",
    "        train_losses.append(train_loss/len(train_loader))\n",
    "        train_accuracy.append(round(train_acc/len(train_loader),2))\n",
    "        \n",
    "        test_loss=0.\n",
    "        test_acc=0.\n",
    "        m.train(mode=False)\n",
    "        with torch.no_grad():\n",
    "            for data,target in test_loader:\n",
    "                data,target=data.to(device),target.to(device)\n",
    "                output=m(data)\n",
    "                loss=criterion(output,target)\n",
    "                loss_value=loss.item()\n",
    "                iter_loss.append(loss_value)\n",
    "                test_loss+=loss_value\n",
    "                acc=compute_accuray(torch.exp(output),target)\n",
    "                test_acc+=acc\n",
    "            \n",
    "        time_elapsed = np.round(time.time() - start_time,2)\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "        test_accuracy.append(round(test_acc/len(test_loader),2))\n",
    "        times.append(time_elapsed)\n",
    "        \n",
    "        print(\"Epoch {}: train loss is {}, train accuracy is {}; test loss is {}, test accuracy is {}, lr is: {}\" .\n",
    "              format(epoch,round(train_loss/len(train_loader),2),\n",
    "                     round(train_acc/len(train_loader),2),\n",
    "                     round(test_loss/len(test_loader),2),\n",
    "                     round(test_acc/len(test_loader),2),\n",
    "                     optimizer.param_groups[0]['lr']))        \n",
    "        if test_loss/len(test_loader)<last_loss:      \n",
    "            name = str(out_dir) + '_' + \".pth\"\n",
    "            save_model_path=os.path.join(out_dir,name)\n",
    "            torch.save(m, save_model_path)\n",
    "            last_loss=test_loss/len(test_loader)\n",
    "        \n",
    "#     df=pd.DataFrame()\n",
    "#     df[\"iteration\"]=np.arange(0,len(iter_loss))\n",
    "#     df[\"loss\"]=iter_loss\n",
    "#     df.to_csv(iter_loss_path,index=False)\n",
    "    \n",
    "#     df=pd.DataFrame()\n",
    "#     df[\"epoch\"]=np.arange(0,nb_epochs)\n",
    "#     df[\"train_loss\"]=train_losses\n",
    "#     df[\"test_loss\"]=test_losses\n",
    "#     df.to_csv(epoch_loss_path,index=False)\n",
    "    \n",
    "    \n",
    "#     plot_accuracy_epoch(train_accuracy, test_accuracy, nb_epochs)\n",
    "#     plot_loss_epoch(train_losses, test_losses, nb_epochs)\n",
    "    \n",
    "    return train_accuracy, test_accuracy, train_losses, test_losses, times\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "colab_type": "code",
    "id": "WCk8J4D1qar2",
    "outputId": "78ce16c9-486f-4ca5-9f19-efd35455530c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000: [===============================>] - ETA 0.4s\n",
      "Epoch 0: train loss is 0.32, train accuracy is 90.68; test loss is 0.11, test accuracy is 96.93, lr is: 0.03\n",
      "  750/60000: [>...............................] - ETA 17.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type LeNet5MNIST_ConvPoly. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Kernel_norelu. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 1: train loss is 0.1, train accuracy is 97.13; test loss is 0.07, test accuracy is 97.91, lr is: 0.03\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 2: train loss is 0.08, train accuracy is 97.86; test loss is 0.06, test accuracy is 98.27, lr is: 0.03\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 3: train loss is 0.06, train accuracy is 98.19; test loss is 0.09, test accuracy is 97.26, lr is: 0.03\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 4: train loss is 0.06, train accuracy is 98.46; test loss is 0.05, test accuracy is 98.67, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 5: train loss is 0.04, train accuracy is 99.06; test loss is 0.04, test accuracy is 98.86, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 6: train loss is 0.03, train accuracy is 99.16; test loss is 0.04, test accuracy is 98.79, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 7: train loss is 0.03, train accuracy is 99.21; test loss is 0.04, test accuracy is 98.85, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 8: train loss is 0.03, train accuracy is 99.26; test loss is 0.04, test accuracy is 98.92, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 9: train loss is 0.03, train accuracy is 99.28; test loss is 0.04, test accuracy is 98.93, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 10: train loss is 0.03, train accuracy is 99.28; test loss is 0.04, test accuracy is 98.88, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 11: train loss is 0.03, train accuracy is 99.31; test loss is 0.04, test accuracy is 98.89, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 12: train loss is 0.03, train accuracy is 99.32; test loss is 0.04, test accuracy is 98.9, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 13: train loss is 0.03, train accuracy is 99.36; test loss is 0.04, test accuracy is 98.94, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 14: train loss is 0.03, train accuracy is 99.35; test loss is 0.05, test accuracy is 98.87, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 15: train loss is 0.03, train accuracy is 99.36; test loss is 0.05, test accuracy is 98.91, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 16: train loss is 0.03, train accuracy is 99.4; test loss is 0.05, test accuracy is 98.89, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 17: train loss is 0.03, train accuracy is 99.4; test loss is 0.05, test accuracy is 98.92, lr is: 0.00030000000000000003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 18: train loss is 0.03, train accuracy is 99.45; test loss is 0.05, test accuracy is 98.98, lr is: 0.00030000000000000003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 19: train loss is 0.03, train accuracy is 99.45; test loss is 0.05, test accuracy is 98.99, lr is: 0.00030000000000000003\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy, train_losses, test_losses, times = train(model, \"LeNet5MNIST_ConvPoly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KwPyjZo8qar5"
   },
   "outputs": [],
   "source": [
    "report = pd.DataFrame({\"Epochs\":range(1,nb_epochs+1),\"Train_Accuracy\":train_accuracy, \"Test_Accuracy\":test_accuracy,\"Train_Loss\":train_losses,\"Test_Loss\":test_losses, \"Time\":times})\n",
    "report.to_csv(\"LeNet5MNIST_ConvPoly.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "colab_type": "code",
    "id": "uLqvWJQbqar7",
    "outputId": "5a4b9e61-5402-434e-9a00-2f16d75db036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 0: train loss is 0.05, train accuracy is 98.75; test loss is 0.06, test accuracy is 98.66, lr is: 0.03\n",
      "  900/60000: [>...............................] - ETA 16.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type LeNet5MNIST_ConvPoly. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Kernel_norelu. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 1: train loss is 0.04, train accuracy is 98.82; test loss is 0.06, test accuracy is 98.57, lr is: 0.03\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 2: train loss is 0.04, train accuracy is 98.87; test loss is 0.04, test accuracy is 98.95, lr is: 0.03\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 3: train loss is 0.04, train accuracy is 98.92; test loss is 0.05, test accuracy is 98.69, lr is: 0.03\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 4: train loss is 0.04, train accuracy is 99.03; test loss is 0.05, test accuracy is 98.68, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 5: train loss is 0.02, train accuracy is 99.44; test loss is 0.04, test accuracy is 99.0, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 6: train loss is 0.02, train accuracy is 99.51; test loss is 0.04, test accuracy is 99.03, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 7: train loss is 0.02, train accuracy is 99.54; test loss is 0.04, test accuracy is 99.13, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 8: train loss is 0.02, train accuracy is 99.56; test loss is 0.04, test accuracy is 99.09, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 9: train loss is 0.02, train accuracy is 99.57; test loss is 0.04, test accuracy is 99.09, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 10: train loss is 0.02, train accuracy is 99.6; test loss is 0.04, test accuracy is 99.11, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 11: train loss is 0.02, train accuracy is 99.59; test loss is 0.05, test accuracy is 99.06, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 12: train loss is 0.02, train accuracy is 99.6; test loss is 0.05, test accuracy is 99.07, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 13: train loss is 0.02, train accuracy is 99.62; test loss is 0.05, test accuracy is 99.11, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 14: train loss is 0.02, train accuracy is 99.64; test loss is 0.05, test accuracy is 99.01, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 15: train loss is 0.02, train accuracy is 99.65; test loss is 0.05, test accuracy is 99.05, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 16: train loss is 0.02, train accuracy is 99.66; test loss is 0.05, test accuracy is 99.08, lr is: 0.003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 17: train loss is 0.02, train accuracy is 99.66; test loss is 0.05, test accuracy is 99.12, lr is: 0.00030000000000000003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 18: train loss is 0.02, train accuracy is 99.68; test loss is 0.05, test accuracy is 99.12, lr is: 0.00030000000000000003\n",
      "60000/60000: [===============================>] - ETA 0.0s\n",
      "Epoch 19: train loss is 0.02, train accuracy is 99.7; test loss is 0.05, test accuracy is 99.13, lr is: 0.00030000000000000003\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy, train_losses, test_losses, times = train(model, \"Lenet5CATDOG_Polynomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "6FfC5ZJEqar-",
    "outputId": "44bd75fd-ecb9-4433-f6bb-346f143fede0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('rho', Parameter containing:\n",
       "              tensor(0.0449, device='cuda:0', requires_grad=True)),\n",
       "             ('c', Parameter containing:\n",
       "              tensor(1., device='cuda:0')),\n",
       "             ('degree', Parameter containing:\n",
       "              tensor(3, device='cuda:0')),\n",
       "             ('gamma', Parameter containing:\n",
       "              tensor(0.5000, device='cuda:0'))])"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv2._parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "Tst7MWwHqasF",
    "outputId": "7d97d459-642e-4e36-f991-66ec04ece40e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5112)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.tensor(0.0448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VqhXtHskqasK"
   },
   "outputs": [],
   "source": [
    "# print(model.conv1.convK1.weight[0:1,0:1])\n",
    "# print(model.conv1.weight[0:1,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7X9_ZE8LqasO"
   },
   "outputs": [],
   "source": [
    "# print(model.conv1.kernel_fn._parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8Sys6bvqasR"
   },
   "outputs": [],
   "source": [
    "# print(model.conv1._parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fztcI3aPqasX"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "model = torch.load(\"/kaggle/input/mnist-models/New folder/Lenet5MNIST_Polynomial(1,3)_.pth\", map_location = torch.device(\"cpu\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ssU39-V5qasc"
   },
   "outputs": [],
   "source": [
    "torch.sigmoid(torch.tensor(1.2526))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EN3JnQJ1qase"
   },
   "outputs": [],
   "source": [
    "def imshowMNIST(img, label):\n",
    "  \n",
    "    img = img.numpy()\n",
    "    img = img.reshape(28,28)\n",
    "    print(label)\n",
    "    plt.axis(\"off\")\n",
    "    fig = plt.figure\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mvIXojy0qasi"
   },
   "outputs": [],
   "source": [
    "layers= {\"conv1\": model.conv1, \"conv2\": model.conv2.conv1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGeNKJYvqasq"
   },
   "outputs": [],
   "source": [
    "images= []\n",
    "labels=[]\n",
    "for img, label in train_loader:\n",
    "    images.append(img)\n",
    "    labels.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F4qM7mjXqasu"
   },
   "outputs": [],
   "source": [
    "image_seven = images[0][labels[0]==7]\n",
    "image_one = images[0][labels[0]==1]\n",
    "image_three = images[0][labels[0]==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXWqb_EUqasx"
   },
   "outputs": [],
   "source": [
    "image_seven.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C7CU9ICCqas0"
   },
   "outputs": [],
   "source": [
    "print(images[0][3].shape)\n",
    "# print(labels[0][1])\n",
    "image = images[0][3]\n",
    "label = labels[0][3]\n",
    "imshowMNIST(images[0][3],labels[0][3])\n",
    "# images[0][1].numpy().transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5k19gqmgqas_"
   },
   "outputs": [],
   "source": [
    "# ax, fig = plt.subplots()\n",
    "imshowMNIST(image_seven[0],labels[0][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DmedjVS-qatC"
   },
   "outputs": [],
   "source": [
    "imshowMNIST(image_one[3],labels[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nll4BAbtqatH"
   },
   "outputs": [],
   "source": [
    "seven = image_seven[0]\n",
    "one = image_one[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CbCTZFmzqatL"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0h9M1eHqatL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-wiHDjzaqatO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RqgeVizMqatS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uI0KBfyYqatX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_tBo2kiOqata"
   },
   "source": [
    "#### Filter Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lksN-RDUqatb"
   },
   "outputs": [],
   "source": [
    "def plot_filters_single_channel_big(t):\n",
    "    \n",
    "    #setting the rows and columns\n",
    "    nrows = t.shape[0]*t.shape[2]\n",
    "    ncols = t.shape[1]*t.shape[3]\n",
    "    \n",
    "    \n",
    "    npimg = np.array(t.numpy(), np.float32)\n",
    "    npimg = npimg.transpose((0, 2, 1, 3))\n",
    "    npimg = npimg.ravel().reshape(nrows, ncols)\n",
    "    \n",
    "    npimg = npimg.T\n",
    "    \n",
    "    fig, ax = plt.subplots()    \n",
    "    imgplot = sns.heatmap(npimg, xticklabels=False, yticklabels=False, cmap='gray', ax=ax, cbar=False)\n",
    "    \n",
    "    \n",
    "def plot_filters_single_channel(t):\n",
    "    \n",
    "    #kernels depth * number of kernels\n",
    "    nplots = t.shape[0]*t.shape[1]\n",
    "    ncols = 12\n",
    "    \n",
    "    nrows = 1 + nplots//ncols\n",
    "    #convert tensor to numpy image\n",
    "    npimg = np.array(t.numpy(), np.float32)\n",
    "    \n",
    "    count = 0\n",
    "    fig = plt.figure(figsize=(ncols, nrows))\n",
    "    \n",
    "    #looping through all the kernels in each channel\n",
    "    for i in range(t.shape[0]):\n",
    "        for j in range(t.shape[1]):\n",
    "            count += 1\n",
    "            ax1 = fig.add_subplot(nrows, ncols, count)\n",
    "            npimg = np.array(t[i, j].numpy(), np.float32)\n",
    "            npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
    "            npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
    "            ax1.imshow(npimg)\n",
    "            ax1.set_title(str(i) + ',' + str(j))\n",
    "            ax1.axis('off')\n",
    "            ax1.set_xticklabels([])\n",
    "            ax1.set_yticklabels([])\n",
    "   \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def plot_filters_multi_channel(t):\n",
    "    \n",
    "    #get the number of kernals\n",
    "    num_kernels = t.shape[0]    \n",
    "    \n",
    "    #define number of columns for subplots\n",
    "    num_cols = 12\n",
    "    #rows = num of kernels\n",
    "    num_rows = num_kernels\n",
    "    \n",
    "    #set the figure size\n",
    "    fig = plt.figure(figsize=(num_cols,num_rows))\n",
    "    \n",
    "    #looping through all the kernels\n",
    "    for i in range(t.shape[0]):\n",
    "        ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
    "        \n",
    "        #for each kernel, we convert the tensor to numpy \n",
    "        npimg = np.array(t[i].numpy(), np.float32)\n",
    "        #standardize the numpy image\n",
    "        npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
    "        npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
    "        npimg = npimg.transpose((1, 2, 0))\n",
    "        ax1.imshow(npimg)\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title(str(i))\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "        \n",
    "    plt.savefig('myimage.png', dpi=100)    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def plot_weights(model, layer_name, single_channel = True, collated = False):\n",
    "  \n",
    "  #extracting the model features at the particular layer number\n",
    "    layer = layers[layer_name]\n",
    "\n",
    "      #checking whether the layer is convolution layer or not \n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        #getting the weight tensor data\n",
    "        weight_tensor = layer.weight.data\n",
    "\n",
    "        if single_channel:\n",
    "            if collated:\n",
    "                plot_filters_single_channel_big(weight_tensor)\n",
    "            else:\n",
    "                plot_filters_single_channel(weight_tensor)\n",
    "\n",
    "        else:\n",
    "            print(weight_tensor.shape)\n",
    "            if weight_tensor.shape[1] == 3:\n",
    "                plot_filters_multi_channel(weight_tensor)\n",
    "            else:\n",
    "                print(\"Can only plot weights with three channels with single channel = False\")\n",
    "\n",
    "    else:\n",
    "        print(\"Can only visualize layers which are convolutional\")\n",
    "        \n",
    "#visualize weights for alexnet - first conv layer\n",
    "# plot_weights(alexnet, 0, single_channel = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aqu2_Wx7qate"
   },
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "plot_weights(model = model, layer_name= \"conv1\", single_channel = True, collated = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rlt2Ihbqati"
   },
   "outputs": [],
   "source": [
    "plot_weights(model = model, layer_name= \"conv2\", single_channel = True, collated = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gsFWjzKhqatk"
   },
   "outputs": [],
   "source": [
    "# plot_weights(model = model, layer_name= \"conv1\", single_channel = False, collated = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hByjfOuiqato"
   },
   "outputs": [],
   "source": [
    "plot_weights(model = model, layer_name= \"conv1\", single_channel = True, collated = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9_4PFALqatr"
   },
   "outputs": [],
   "source": [
    "plot_weights(model = model, layer_name= \"conv2\", single_channel = True, collated = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DbVDPImQqatu"
   },
   "source": [
    "#### Occlusion Experiments\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgyvPBSkqatu"
   },
   "outputs": [],
   "source": [
    "#custom function to conduct occlusion experiments\n",
    "\n",
    "def occlusion(model, image, label, occ_size = 15, occ_stride = 5, occ_pixel = 0.5):\n",
    "  \n",
    "    #get the width and height of the image\n",
    "    image_copy = image.reshape(28,28)\n",
    "    width, height = image_copy.shape[0], image_copy.shape[1]\n",
    "    print(width)\n",
    "    print(height)\n",
    "  \n",
    "    #setting the output image width and height\n",
    "    output_height = int(np.ceil((height-occ_size)/occ_stride))\n",
    "    print(\"output_height: \", output_height)\n",
    "    output_width = int(np.ceil((width-occ_size)/occ_stride))\n",
    "    print(\"output_width: \", output_width)\n",
    "    #create a white image of sizes we defined\n",
    "    heatmap = torch.zeros((output_height, output_width))\n",
    "    \n",
    "    #iterate all the pixels in each column\n",
    "    for h in range(0, height):\n",
    "        for w in range(0, width):\n",
    "            \n",
    "            h_start = h*occ_stride\n",
    "            w_start = w*occ_stride\n",
    "            h_end = min(height, h_start + occ_size)\n",
    "            w_end = min(width, w_start + occ_size)\n",
    "            \n",
    "            if (w_end) >= width or (h_end) >= height:\n",
    "                continue\n",
    "            \n",
    "            input_image = image.clone().detach()\n",
    "            input_image = input_image.reshape(1,1,28,28)\n",
    "            \n",
    "            #replacing all the pixel information in the image with occ_pixel(grey) in the specified location\n",
    "            input_image[:,:, w_start:w_end, h_start:h_end] = occ_pixel\n",
    "            \n",
    "            #run inference on modified image\n",
    "            \n",
    "            output = torch.exp(model(input_image))\n",
    "#             print(output.tolist())\n",
    "            prob = output.tolist()[0][label]\n",
    "            print(prob)\n",
    "            \n",
    "            #setting the heatmap location to probability value\n",
    "            heatmap[h, w] = prob \n",
    "\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "InwYPfbsqatz"
   },
   "outputs": [],
   "source": [
    "imshowMNIST(images[0][1],labels[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ey7x7QcCqat5"
   },
   "outputs": [],
   "source": [
    "heatmap =  occlusion(model, image, label.item())\n",
    "imgplot = sns.heatmap(heatmap, xticklabels=False, yticklabels=False)\n",
    "figure = imgplot.get_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZN4bMFTqat-"
   },
   "source": [
    "> ####  Activation Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SUXnxA46qat_"
   },
   "outputs": [],
   "source": [
    " list(model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZekqHUxCqauB"
   },
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "\n",
    "\n",
    "model.conv1.register_forward_hook(get_activation('conv1'))\n",
    "model.conv2.register_forward_hook(get_activation('conv2'))\n",
    "model.fc1.register_forward_hook(get_activation('fc1'))\n",
    "model.fc2.register_forward_hook(get_activation('fc2'))\n",
    "model.fc3.register_forward_hook(get_activation('fc3'))\n",
    "x = one.reshape(1,1,28,28)\n",
    "output = model(x)\n",
    "print(activation['conv1'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WothtOCQqauI"
   },
   "outputs": [],
   "source": [
    "# activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_yH4yOkCqauL"
   },
   "outputs": [],
   "source": [
    "act = activation['conv1'].squeeze()\n",
    "print(act.shape)\n",
    "fig, axarr = plt.subplots(act.size(0), figsize=(10,10))\n",
    "for idx in range(act.size(0)):\n",
    "    axarr[idx].imshow(act[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJZxmw85qauO"
   },
   "outputs": [],
   "source": [
    "act = activation['conv2'].squeeze()\n",
    "print(act.shape)\n",
    "fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(8,8))\n",
    "for ax, feature in zip(ax.flatten(), act):\n",
    "    ax.imshow(feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a7vGntd-qauS"
   },
   "source": [
    "### Activation Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9xZafufAqauS"
   },
   "outputs": [],
   "source": [
    "list(model.children())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYrKlaLvqauY"
   },
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    def __init__(self, module):\n",
    "        self.hook = module.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.features = torch.tensor(output,requires_grad=True).cuda()\n",
    "    def close(self):\n",
    "        self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "goJoiF0Yqaud"
   },
   "outputs": [],
   "source": [
    "activations = SaveFeatures(list(model.children())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UR15pm7fqaug"
   },
   "outputs": [],
   "source": [
    "#list(model.children())[0].register_forward_hook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yXiuR6bjqauj"
   },
   "outputs": [],
   "source": [
    "#activations.f[0, 1]\n",
    "#activations.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBA-LhIGqaum"
   },
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Um5ouglAqauq"
   },
   "outputs": [],
   "source": [
    "import  cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MuFlNoryqauu"
   },
   "outputs": [],
   "source": [
    "# class FilterVisualizer_Old():\n",
    "#     def __init__(self,  model,size=28, upscaling_steps=12, upscaling_factor=1.2):\n",
    "#         self.size, self.upscaling_steps, self.upscaling_factor = size, upscaling_steps, upscaling_factor\n",
    "#         self.model = model\n",
    "#         self.model.eval()\n",
    "\n",
    "#     def visualize(self, layer, filter, lr=0.1, opt_steps=20, blur=None):\n",
    "#         sz = self.size\n",
    "#         img = np.uint8(np.random.uniform(150, 180, (1,sz, sz)))/255  # generate random image\n",
    "#         activations = SaveFeatures(list(self.model.children())[layer])  # register hook\n",
    "#         print(img.shape)\n",
    "#         for _ in range(self.upscaling_steps):  # scale the image up upscaling_steps times\n",
    "# #             train_tfms, val_tfms = tfms_from_model(self.model, sz)\n",
    "#             img_var = torch.tensor(img[None], dtype=torch.double,requires_grad=True)  # convert image to Variable that requires grad\n",
    "#             optimizer = torch.optim.Adam([img_var], lr=lr, weight_decay=1e-6)\n",
    "#             for n in range(opt_steps):  # optimize pixel values for opt_steps times\n",
    "#                 optimizer.zero_grad()\n",
    "#                 #print(img_var.shape)\n",
    "#                 self.model(img_var)\n",
    "#                 loss = -activations.features[0, filter].mean()\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "#             img = img_var.data.cpu().numpy()[0].transpose(1,2,0)\n",
    "#             self.output = img\n",
    "#             sz = int(self.upscaling_factor * sz)  # calculate new image size\n",
    "#             img = cv2.resize(img, (sz, sz), interpolation = cv2.INTER_CUBIC)  # scale image up\n",
    "#             if blur is not None: img = cv2.blur(img,(blur,blur))  # blur image to reduce high frequency patterns\n",
    "#         self.save(layer, filter)\n",
    "#         activations.close()\n",
    "        \n",
    "#     def save(self, layer, filter):\n",
    "#         plt.imsave(\"layer_\"+str(layer)+\"_filter_\"+str(filter)+\".jpg\", np.clip(self.output, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BakP7hraqauw"
   },
   "outputs": [],
   "source": [
    "img = np.uint8(np.random.uniform(150, 180, (28, 28, 3)))/255\n",
    "print(img.shape)\n",
    "print(img[None].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6thq7jVZqauy"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z7XJkxKaqau0"
   },
   "outputs": [],
   "source": [
    "class FilterVisualizer():\n",
    "    def __init__(self,  model,size=28, upscaling_steps=12, upscaling_factor=1.2):\n",
    "        self.size, self.upscaling_steps, self.upscaling_factor = size, upscaling_steps, upscaling_factor\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "    def visualize(self, layer, filter, lr=0.1, opt_steps=20, blur=None):\n",
    "        sz = self.size\n",
    "        img = np.uint8(np.random.uniform(150, 180, (1,sz, sz)))/255  # generate random image\n",
    "        activations = SaveFeatures(list(self.model.children())[layer])  # register hook\n",
    "        \n",
    "        #for _ in range(self.upscaling_steps):  # scale the image up upscaling_steps times\n",
    "            #train_tfms, val_tfms = tfms_from_model(self.model, sz)\n",
    "        img_var = torch.tensor(img[None], dtype=torch.double,requires_grad=True)  # convert image to Variable that requires grad\n",
    "        optimizer = torch.optim.Adam([img_var], lr=lr, weight_decay=1e-6)\n",
    "        for n in range(opt_steps):  # optimize pixel values for opt_steps times\n",
    "            optimizer.zero_grad()\n",
    "            #print(img_var.shape)\n",
    "            self.model(img_var)\n",
    "            loss = -activations.features[0, filter].mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        img = img_var.data.cpu().numpy()[0].transpose(1,2,0)\n",
    "        print(img.shape)\n",
    "        self.output = cv2.resize(img, (sz, sz))#img\n",
    "        sz = int(self.upscaling_factor * sz)  # calculate new image size\n",
    "        img = cv2.resize(img, (sz, sz), interpolation = cv2.INTER_CUBIC)  # scale image up\n",
    "        if blur is not None: img = cv2.blur(img,(blur,blur))  # blur image to reduce high frequency patterns\n",
    "        self.save(layer, filter)\n",
    "        activations.close()\n",
    "        \n",
    "    def save(self, layer, filter):\n",
    "        #print(self.output.reshape(1,28,28))\n",
    "        plt.imsave(\"layer_\"+str(layer)+\"_filter_\"+str(filter)+\".jpg\",np.clip(self.output, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I4j41Ot7qau-"
   },
   "outputs": [],
   "source": [
    "model = model.double()\n",
    "layer = 2\n",
    "filter = 15\n",
    "FV = FilterVisualizer(model, upscaling_steps=5, upscaling_factor=1.2)\n",
    "FV.visualize(layer, filter, blur=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CGG4ixgGqavA"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"/kaggle/input/gen-imgage/layer_2_filter_0.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLEbF0ACqavL"
   },
   "outputs": [],
   "source": [
    "img = torch.tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71ML7F2dqavP"
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsJ2nnWJqavR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYSZ_BMCqavU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pxgzw25mqave"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crijb4KAqavf"
   },
   "outputs": [],
   "source": [
    "21952/(28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_hBv2p8iqavh"
   },
   "source": [
    "#### Saliency Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "56usG_vQqavj"
   },
   "outputs": [],
   "source": [
    "\n",
    "X=image.reshape(1,1,28,28)\n",
    "X.requires_grad_()\n",
    "scores = torch.exp(model(X))\n",
    "score_max_index = scores.argmax()\n",
    "score_max = scores[0,score_max_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "75_sinueqavl"
   },
   "outputs": [],
   "source": [
    "score_max.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lCbgSqRqqavn"
   },
   "outputs": [],
   "source": [
    "saliency, _ = torch.max(X.grad.data.abs(),dim=1)\n",
    "\n",
    "\n",
    "# code to plot the saliency map as a heatmap\n",
    "plt.imshow(saliency[0], cmap=plt.cm.hot)\n",
    "# plt.imshow(images[0][1])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MKe9kiSlqavq"
   },
   "outputs": [],
   "source": [
    "imshowMNIST(images[0][1],labels[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLrwwYDnqavt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "MNIST_Kerv.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02aeac86178e43b18e0efb5eab42a22b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d306ce7f003b4668a0f3ff8d446ccaec",
      "placeholder": "​",
      "style": "IPY_MODEL_67d18c7024e64d9a822bb13fa8643c5e",
      "value": " 1654784/? [00:15&lt;00:00, 235377.86it/s]"
     }
    },
    "07d69766a8e44091b382b02a26031162": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "096d7b40a4f044279267b42cdda8bfc8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d23f105711f414cade3a9de2a39d144": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d278877619a14ee48b67a9255466b6e5",
       "IPY_MODEL_02aeac86178e43b18e0efb5eab42a22b"
      ],
      "layout": "IPY_MODEL_5e811c3e7eca416990d2c7ac975e3a30"
     }
    },
    "179909d4cbb4448cb72e040824f0821a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "187485a346c84d049186ef2b2ba71a9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "28b84acde55449559884a823b9702987": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d518aecab0c40fc93825956e70680dd",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c4eca6acf341433db0b9343d9de690c8",
      "value": 1
     }
    },
    "2e6bc382ce8847078fb82e8054e66ea3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07d69766a8e44091b382b02a26031162",
      "placeholder": "​",
      "style": "IPY_MODEL_179909d4cbb4448cb72e040824f0821a",
      "value": " 9920512/? [00:20&lt;00:00, 1235648.20it/s]"
     }
    },
    "369ef7765e944ea3b08c9eb7b2868d71": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3de48ae8713d4373a021c508777b0e90": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4dda8be814c14afd81aaf1c13726ebd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5291583f275b478a9949b39abae05af3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e811c3e7eca416990d2c7ac975e3a30": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f8cb837ef1f4d2ca58f6cc790aa865b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b83a3812c8445c5ad020d9c235dcadc",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7871ae2e405c4f9c9003365c94523b4d",
      "value": 0
     }
    },
    "67d18c7024e64d9a822bb13fa8643c5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "727e12f3180b443696bbfa09949cde16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76efe726779b4ac2b9c53d3bffb622c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_727e12f3180b443696bbfa09949cde16",
      "placeholder": "​",
      "style": "IPY_MODEL_4dda8be814c14afd81aaf1c13726ebd5",
      "value": " 0/4542 [00:00&lt;?, ?it/s]"
     }
    },
    "7871ae2e405c4f9c9003365c94523b4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7c9500cf7d6d4bb3b376c1e44bd21cab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7dfccf0db5bc412483986ea19ac2de1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc3e3d5a8b5348b1aa4eb6965e1c6874",
       "IPY_MODEL_2e6bc382ce8847078fb82e8054e66ea3"
      ],
      "layout": "IPY_MODEL_5291583f275b478a9949b39abae05af3"
     }
    },
    "8b83a3812c8445c5ad020d9c235dcadc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99d802a9e0434549a7f73b26e0b7f1f3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d518aecab0c40fc93825956e70680dd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2029f13840c42ed8b5c556a021ae6d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5f8cb837ef1f4d2ca58f6cc790aa865b",
       "IPY_MODEL_76efe726779b4ac2b9c53d3bffb622c6"
      ],
      "layout": "IPY_MODEL_b941015c9f6b4526836602515ffebcc9"
     }
    },
    "b941015c9f6b4526836602515ffebcc9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4eca6acf341433db0b9343d9de690c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d1bd301da7f14ce3b1efb9905affa766": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d278877619a14ee48b67a9255466b6e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3de48ae8713d4373a021c508777b0e90",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7c9500cf7d6d4bb3b376c1e44bd21cab",
      "value": 1
     }
    },
    "d306ce7f003b4668a0f3ff8d446ccaec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e050029c75ad4d858ae2d1c53f1c1b36": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99d802a9e0434549a7f73b26e0b7f1f3",
      "placeholder": "​",
      "style": "IPY_MODEL_187485a346c84d049186ef2b2ba71a9f",
      "value": " 32768/? [00:00&lt;00:00, 37947.14it/s]"
     }
    },
    "e9a428ee92d344ffb8b552b52724cdae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_28b84acde55449559884a823b9702987",
       "IPY_MODEL_e050029c75ad4d858ae2d1c53f1c1b36"
      ],
      "layout": "IPY_MODEL_d1bd301da7f14ce3b1efb9905affa766"
     }
    },
    "fc3e3d5a8b5348b1aa4eb6965e1c6874": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_096d7b40a4f044279267b42cdda8bfc8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_369ef7765e944ea3b08c9eb7b2868d71",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
